{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import time\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "\n",
    "import torch\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "#from scripts.differentiable_pfn_evaluation import eval_model_range\n",
    "# No string\n",
    "from scripts.model_builder import get_model, get_default_spec, save_model, load_model\n",
    "from scripts.transformer_prediction_interface import transformer_predict, get_params_from_config, load_model_workflow, TabPFNClassifier\n",
    "\n",
    "from scripts.model_configs import *\n",
    "\n",
    "from datasets import load_openml_list, open_cc_dids, open_cc_valid_dids\n",
    "from priors.utils import plot_prior, plot_features\n",
    "from priors.utils import uniform_int_sampler_f\n",
    "\n",
    "from scripts.tabular_metrics import calculate_score_per_method, calculate_score\n",
    "# No string\n",
    "#from scripts.tabular_evaluation import evaluate\n",
    "\n",
    "from priors.differentiable_prior import DifferentiableHyperparameterList, draw_random_style, merge_style_with_info\n",
    "from scripts import tabular_metrics\n",
    "from notebook_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "large_datasets = True\n",
    "max_samples = 10000 if large_datasets else 5000\n",
    "bptt = 10000 if large_datasets else 3000\n",
    "suite='cc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cpu'\n",
    "base_path = '.'\n",
    "max_features = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_models(model_string):\n",
    "    print(model_string)\n",
    "\n",
    "    for i in range(80):\n",
    "        for e in range(50):\n",
    "            exists = Path(os.path.join(base_path, f'models_diff/prior_diff_real_checkpoint{model_string}_n_{i}_epoch_{e}.cpkt')).is_file()\n",
    "            if exists:\n",
    "                print(os.path.join(base_path, f'models_diff/prior_diff_real_checkpoint{model_string}_n_{i}_epoch_{e}.cpkt'))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_function(config_sample, i, add_name='', maximum_runtime = 15):\n",
    "    start_time = time.time()\n",
    "    N_epochs_to_save = 50\n",
    "    def save_callback(model, epoch):\n",
    "        if not hasattr(model, 'last_saved_epoch'):\n",
    "            model.last_saved_epoch = 0\n",
    "        if ((time.time() - start_time) / (maximum_runtime * 60 / N_epochs_to_save)) > model.last_saved_epoch:\n",
    "            print('Saving model..')\n",
    "            config_sample['epoch_in_training'] = epoch\n",
    "            save_model(model, base_path, f'models_diff/prior_diff_real_checkpoint{add_name}_n_{i}_epoch_{model.last_saved_epoch}.cpkt',\n",
    "                           config_sample)\n",
    "            model.last_saved_epoch = model.last_saved_epoch + 1 # TODO: Rename to checkpoint\n",
    "    \n",
    "    model = get_model(config_sample\n",
    "                      , device\n",
    "                      , should_train=True\n",
    "                      , verbose=1\n",
    "                      , epoch_callback = save_callback)\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Define prior settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def reload_config(config_type='causal', task_type='multiclass', longer=0):\n",
    "    config = get_prior_config(config_type=config_type)\n",
    "    \n",
    "    config['prior_type'], config['differentiable'], config['flexible'] = 'mlp', True, True\n",
    "    \n",
    "    model_string = ''\n",
    "    \n",
    "    config['epochs'] = 12000\n",
    "    config['recompute_attn'] = False\n",
    "\n",
    "    config['max_num_classes'] = 10\n",
    "    config['num_classes'] = uniform_int_sampler_f(2, config['max_num_classes'])\n",
    "    config['balanced'] = False\n",
    "    model_string = model_string + '_multiclass'\n",
    "    \n",
    "    model_string = model_string + '_'+datetime.now().strftime(\"%m_%d_%Y_%H_%M_%S\")\n",
    "    \n",
    "    return config, model_string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Visualize Prior samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr': lr, Type: UniformFloat, Range: [0.0001, 0.00015], Default: 0.0001224745, on log-scale, 'dropout': dropout, Type: Categorical, Choices: {0.0}, Default: 0.0, 'emsize': emsize, Type: Categorical, Choices: {256}, Default: 256, 'emsize_f': 256, 'batch_size': batch_size, Type: Categorical, Choices: {64, 128}, Default: 64, 'nlayers': nlayers, Type: Categorical, Choices: {12}, Default: 12, 'num_features': 100, 'nhead': nhead, Type: Categorical, Choices: {4}, Default: 4, 'nhid_factor': 2, 'bptt': 50, 'eval_positions': None, 'seq_len_used': 50, 'sampling': 'normal', 'epochs': 12000, 'num_steps': 100, 'verbose': False, 'mix_activations': False, 'pre_sample_causes': True, 'multiclass_type': 'rank', 'nan_prob_unknown_reason_reason_prior': nan_prob_unknown_reason_reason_prior, Type: Categorical, Choices: {0.5}, Default: 0.5, 'categorical_feature_p': categorical_feature_p, Type: Categorical, Choices: {0.0, 0.1, 0.2}, Default: 0.0, 'nan_prob_no_reason': nan_prob_no_reason, Type: Categorical, Choices: {0.0, 0.1}, Default: 0.0, 'nan_prob_unknown_reason': nan_prob_unknown_reason, Type: Categorical, Choices: {0.0}, Default: 0.0, 'nan_prob_a_reason': nan_prob_a_reason, Type: Categorical, Choices: {0.0}, Default: 0.0, 'max_num_classes': 10, 'num_classes': <function <lambda>.<locals>.<lambda> at 0x7fd628b13290>, 'noise_type': noise_type, Type: Categorical, Choices: {Gaussian}, Default: Gaussian, 'balanced': False, 'normalize_to_ranking': normalize_to_ranking, Type: Categorical, Choices: {False}, Default: False, 'set_value_to_nan': set_value_to_nan, Type: Categorical, Choices: {0.5, 0.2, 0.0}, Default: 0.5, 'normalize_by_used_features': True, 'num_features_used': {'uniform_int_sampler_f(3,max_features)': <function <lambda>.<locals>.<lambda> at 0x7fd628b13a70>}, 'num_categorical_features_sampler_a': -1.0, 'differentiable_hyperparameters': {'prior_bag_exp_weights_1': {'distribution': 'uniform', 'min': 2.0, 'max': 10.0}, 'num_layers': {'distribution': 'meta_gamma', 'max_alpha': 2, 'max_scale': 3, 'round': True, 'lower_bound': 2}, 'prior_mlp_hidden_dim': {'distribution': 'meta_gamma', 'max_alpha': 3, 'max_scale': 100, 'round': True, 'lower_bound': 4}, 'prior_mlp_dropout_prob': {'distribution': 'meta_beta', 'scale': 0.6, 'min': 0.1, 'max': 5.0}, 'noise_std': {'distribution': 'meta_trunc_norm_log_scaled', 'max_mean': 0.3, 'min_mean': 0.0001, 'round': False, 'lower_bound': 0.0}, 'init_std': {'distribution': 'meta_trunc_norm_log_scaled', 'max_mean': 10.0, 'min_mean': 0.01, 'round': False, 'lower_bound': 0.0}, 'num_causes': {'distribution': 'meta_gamma', 'max_alpha': 3, 'max_scale': 7, 'round': True, 'lower_bound': 2}, 'is_causal': {'distribution': 'meta_choice', 'choice_values': [True, False]}, 'pre_sample_weights': {'distribution': 'meta_choice', 'choice_values': [True, False]}, 'y_is_effect': {'distribution': 'meta_choice', 'choice_values': [True, False]}, 'sampling': {'distribution': 'meta_choice', 'choice_values': ['normal', 'mixed']}, 'prior_mlp_activations': {'distribution': 'meta_choice_mixed', 'choice_values': [<class 'torch.nn.modules.activation.Tanh'>, <class 'torch.nn.modules.linear.Identity'>, <class 'torch.nn.modules.activation.ReLU'>]}, 'block_wise_dropout': {'distribution': 'meta_choice', 'choice_values': [True, False]}, 'sort_features': {'distribution': 'meta_choice', 'choice_values': [True, False]}, 'in_clique': {'distribution': 'meta_choice', 'choice_values': [True, False]}, 'outputscale': {'distribution': 'meta_trunc_norm_log_scaled', 'max_mean': 10.0, 'min_mean': 1e-05, 'round': False, 'lower_bound': 0}, 'lengthscale': {'distribution': 'meta_trunc_norm_log_scaled', 'max_mean': 10.0, 'min_mean': 1e-05, 'round': False, 'lower_bound': 0}, 'noise': {'distribution': 'meta_choice', 'choice_values': [1e-05, 0.0001, 0.01]}, 'output_multiclass_ordered_p': {'distribution': 'uniform', 'min': 0.0, 'max': 0.5}, 'multiclass_type': {'distribution': 'meta_choice', 'choice_values': ['value', 'rank']}}, 'prior_type': 'mlp', 'differentiable': True, 'flexible': True, 'recompute_attn': False}\n"
     ]
    }
   ],
   "source": [
    "config, model_string = reload_config(longer=1)\n",
    "print(config)\n",
    "config['bptt_extra_samples'] = None\n",
    "\n",
    "# diff\n",
    "config['output_multiclass_ordered_p'] = 0.\n",
    "del config['differentiable_hyperparameters']['output_multiclass_ordered_p']\n",
    "\n",
    "config['multiclass_type'] = 'rank'\n",
    "del config['differentiable_hyperparameters']['multiclass_type']\n",
    "\n",
    "config['sampling'] = 'normal' # vielleicht schlecht?\n",
    "del config['differentiable_hyperparameters']['sampling']\n",
    "\n",
    "config['pre_sample_causes'] = True\n",
    "# end diff\n",
    "\n",
    "config['multiclass_loss_type'] = 'nono' # 'compatible'\n",
    "config['normalize_to_ranking'] = False # False\n",
    "\n",
    "config['categorical_feature_p'] = .2 # diff: .0\n",
    "\n",
    "# turn this back on in a random search!?\n",
    "config['nan_prob_no_reason'] = .0\n",
    "config['nan_prob_unknown_reason'] = .0 # diff: .0\n",
    "config['set_value_to_nan'] = .1 # diff: 1.\n",
    "\n",
    "config['normalize_with_sqrt'] = False\n",
    "\n",
    "config['new_mlp_per_example'] = True\n",
    "config['prior_mlp_scale_weights_sqrt'] = True\n",
    "config['batch_size_per_gp_sample'] = None\n",
    "\n",
    "config['normalize_ignore_label_too'] = False\n",
    "\n",
    "config['differentiable_hps_as_style'] = False\n",
    "config['max_eval_pos'] = 1000\n",
    "\n",
    "config['random_feature_rotation'] = True\n",
    "config['rotate_normalized_labels'] = True\n",
    "\n",
    "config[\"mix_activations\"] = False # False heisst eig True\n",
    "\n",
    "config['emsize'] = 512 # 512 in the paper\n",
    "config['emsize_f'] = 100\n",
    "config['nhead'] = config['emsize'] // 8 \n",
    "config['bptt'] = 1024+128\n",
    "config['canonical_y_encoder'] = False\n",
    "config['nlayers'] = 2\n",
    "\n",
    "    \n",
    "config['aggregate_k_gradients'] = 8\n",
    "config['batch_size'] = 2 * config['aggregate_k_gradients']\n",
    "config['num_steps'] = 1024//config['aggregate_k_gradients']\n",
    "config['epochs'] = 400\n",
    "config['total_available_time_in_s'] = None #60*60*22 # 22 hours for some safety...\n",
    "\n",
    "config['train_mixed_precision'] = True\n",
    "config['efficient_eval_masking'] = True\n",
    "\n",
    "config_sample = evaluate_hypers(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skipping\n"
     ]
    }
   ],
   "source": [
    "%%script echo skipping\n",
    "\n",
    "config_sample['batch_size'] = 4\n",
    "model = get_model(config_sample, device, should_train=False, verbose=2) # , state_dict=model[2].state_dict()\n",
    "(hp_embedding, data, _), targets, single_eval_pos = next(iter(model[3]))\n",
    "\n",
    "from utils import normalize_data\n",
    "fig = plt.figure(figsize=(8, 8))\n",
    "N = 100\n",
    "plot_features(data[0:N, 0, 0:4], targets[0:N, 0], fig=fig)\n",
    "\n",
    "d = np.concatenate([data[:, 0, :].T, np.expand_dims(targets[:, 0], -1).T])\n",
    "d[np.isnan(d)] = 0\n",
    "c = np.corrcoef(d)\n",
    "plt.matshow(np.abs(c), vmin=0, vmax=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using style prior: True\n",
      "Using cpu:0 device\n",
      "Using a Transformer with 5.03 M parameters\n"
     ]
    }
   ],
   "source": [
    "model = get_model(config_sample, device, should_train=True, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using style prior: True\n",
      "Using cpu:0 device\n",
      "Using a Transformer with 5.03 M parameters\n"
     ]
    }
   ],
   "source": [
    "model = train_function(config_sample, i=0, add_name = '_Testing_1_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 5.03 M parameters\n"
     ]
    }
   ],
   "source": [
    "model = TabPFNClassifier(device=device, base_path='/Users/antanas/GitRepo/TabPFN/tabpfn',\n",
    "                         N_ensemble_configurations=32, model_string = '_Second_test_', epoch = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(OrderedDict([('transformer_encoder.layers.0.self_attn.in_proj_weight',\n",
       "               tensor([[ 0.0454,  0.0307, -0.0531,  ..., -0.0323, -0.0213,  0.0488],\n",
       "                       [ 0.0401,  0.0006,  0.0315,  ...,  0.0326,  0.0319, -0.0293],\n",
       "                       [ 0.0345, -0.0355,  0.0251,  ...,  0.0536,  0.0120, -0.0469],\n",
       "                       ...,\n",
       "                       [ 0.0071, -0.0001,  0.0325,  ..., -0.0441, -0.0508,  0.0288],\n",
       "                       [-0.0304,  0.0268, -0.0551,  ..., -0.0501,  0.0418,  0.0033],\n",
       "                       [ 0.0049,  0.0376, -0.0540,  ..., -0.0370, -0.0142, -0.0328]])),\n",
       "              ('transformer_encoder.layers.0.self_attn.in_proj_bias',\n",
       "               tensor([ 0.0006,  0.0011,  0.0014,  ..., -0.0017,  0.0017,  0.0017])),\n",
       "              ('transformer_encoder.layers.0.self_attn.out_proj.weight',\n",
       "               tensor([[ 0.0016,  0.0017,  0.0018,  ...,  0.0017, -0.0017, -0.0017],\n",
       "                       [-0.0004, -0.0008, -0.0007,  ..., -0.0007,  0.0007,  0.0008],\n",
       "                       [-0.0014, -0.0012, -0.0013,  ..., -0.0012,  0.0013,  0.0012],\n",
       "                       ...,\n",
       "                       [ 0.0009,  0.0010,  0.0010,  ...,  0.0011, -0.0009, -0.0008],\n",
       "                       [-0.0017, -0.0019, -0.0019,  ..., -0.0018,  0.0019,  0.0019],\n",
       "                       [ 0.0011,  0.0013,  0.0013,  ...,  0.0013, -0.0013, -0.0013]])),\n",
       "              ('transformer_encoder.layers.0.self_attn.out_proj.bias',\n",
       "               tensor([-1.5080e-03,  7.0123e-04,  9.3390e-04,  2.2117e-04, -1.5239e-03,\n",
       "                       -1.4801e-03, -1.4473e-03,  1.3720e-03,  1.3915e-03, -6.4472e-04,\n",
       "                       -1.3897e-03,  1.2090e-03,  1.2050e-03,  1.0778e-03, -4.2904e-04,\n",
       "                        1.5359e-03,  1.0215e-03,  1.4682e-03,  1.4948e-03,  1.3297e-03,\n",
       "                       -1.6651e-03, -1.4727e-03,  8.7678e-04,  1.4462e-03, -1.4379e-03,\n",
       "                        1.6009e-03, -1.5443e-03,  1.0639e-03,  1.3301e-03,  1.4216e-03,\n",
       "                        1.5443e-03,  1.4116e-03, -1.5051e-03, -1.3895e-03,  1.0746e-03,\n",
       "                        1.4580e-03,  1.1223e-03,  1.5319e-03, -1.0289e-03, -1.1755e-03,\n",
       "                        1.1251e-03, -1.1284e-03, -1.4654e-03,  1.3514e-03, -1.4278e-03,\n",
       "                        1.1897e-03, -1.5030e-03, -1.1737e-03, -3.1968e-04,  1.4725e-03,\n",
       "                        1.3161e-03, -1.3132e-03,  1.4550e-03, -1.3503e-03, -1.2656e-03,\n",
       "                       -1.5577e-03,  1.0636e-03,  1.4782e-03, -1.5303e-03,  1.1919e-03,\n",
       "                        1.1988e-03,  1.1360e-03, -1.4231e-03, -1.1941e-03,  1.4491e-03,\n",
       "                        1.2192e-03, -1.5084e-03, -1.3770e-03, -1.2895e-03, -1.3181e-03,\n",
       "                       -1.3297e-03,  1.0531e-03,  1.6058e-03,  8.8591e-04,  1.5553e-03,\n",
       "                       -1.1118e-03, -1.5868e-03, -1.3474e-03, -1.3993e-03, -1.3805e-03,\n",
       "                       -1.5124e-03,  1.4978e-03,  1.2675e-03, -1.5417e-03,  1.2257e-03,\n",
       "                       -1.4635e-03,  1.0942e-03,  1.5595e-03, -7.3425e-04, -1.5426e-03,\n",
       "                        1.3629e-03,  1.4444e-03,  1.4126e-03,  1.2188e-03,  1.4831e-03,\n",
       "                        1.5162e-03,  1.3878e-03, -8.6897e-04,  1.3580e-03,  1.1083e-03,\n",
       "                        4.9609e-04,  1.0512e-03, -1.5621e-03,  1.5778e-03, -1.4932e-03,\n",
       "                        1.5055e-03,  1.4376e-03,  1.4607e-03, -1.1810e-04, -1.1955e-03,\n",
       "                       -1.1840e-03,  1.3911e-03, -1.4953e-03, -1.2456e-03, -1.5551e-03,\n",
       "                       -1.5394e-03, -1.4957e-03, -1.0021e-03,  1.5050e-03, -1.3951e-03,\n",
       "                        1.0510e-03, -1.5500e-03, -1.4332e-03,  1.2893e-03, -1.1605e-03,\n",
       "                        1.4886e-03,  1.4332e-03,  1.4943e-03,  1.3055e-03, -8.8817e-04,\n",
       "                        1.2333e-03,  1.6222e-03,  7.4743e-05,  1.4211e-03,  1.5318e-03,\n",
       "                       -1.5303e-03, -1.5280e-03, -1.5838e-03,  6.4372e-04,  1.5845e-03,\n",
       "                       -1.3163e-03,  1.5934e-03, -6.2058e-04,  1.1509e-03, -1.1163e-03,\n",
       "                       -9.1464e-05, -1.6225e-03,  1.2786e-03, -1.6040e-03, -1.3028e-03,\n",
       "                        1.5772e-03, -1.4706e-03, -1.4437e-03, -1.1622e-03, -1.3628e-03,\n",
       "                       -1.3661e-03,  1.5102e-03, -1.5093e-03, -1.4703e-03, -1.3487e-03,\n",
       "                        1.5509e-03,  1.4246e-03, -1.5504e-03,  7.1595e-04,  1.2114e-03,\n",
       "                        1.4243e-03, -1.4648e-03, -1.4239e-03, -1.5905e-03,  1.3044e-03,\n",
       "                       -1.2831e-03, -1.0183e-03,  1.3867e-03,  1.4799e-03, -1.5083e-03,\n",
       "                        5.9310e-04, -1.4335e-03, -1.2523e-03, -1.5213e-03,  1.0830e-03,\n",
       "                       -2.3239e-04,  1.5452e-03,  1.2430e-03,  1.4194e-03,  1.2420e-03,\n",
       "                        7.4403e-04,  1.4967e-03, -9.8162e-04, -1.4355e-03, -1.5182e-03,\n",
       "                        9.0797e-04,  1.3996e-03,  1.5486e-03, -1.2553e-03, -1.3358e-03,\n",
       "                        1.3078e-03, -1.4803e-03,  1.5078e-03, -1.5070e-03, -1.4874e-03,\n",
       "                       -1.1833e-03, -1.4254e-03,  1.5021e-03,  1.6053e-03, -1.7541e-03,\n",
       "                        1.3181e-03,  1.3104e-03,  1.3847e-03,  1.3528e-03, -1.3563e-03,\n",
       "                       -1.3376e-03, -1.2878e-03,  1.5239e-03,  1.2883e-03,  1.3521e-03,\n",
       "                        1.4961e-03, -1.7704e-03, -1.3841e-03,  1.5014e-03,  1.0910e-03,\n",
       "                        1.5082e-03, -1.4904e-03, -1.4627e-03,  1.3496e-03, -5.0757e-04,\n",
       "                        9.6488e-04,  1.2850e-03, -1.4476e-03,  1.2012e-03, -1.3163e-03,\n",
       "                       -1.4451e-03, -1.5014e-03,  1.3843e-03,  1.5116e-03, -1.4603e-03,\n",
       "                       -1.1063e-03,  9.3787e-04, -7.0506e-04,  1.4034e-03,  1.2924e-03,\n",
       "                        1.5619e-03, -1.3073e-03, -1.5060e-03, -1.4763e-03,  1.5439e-03,\n",
       "                       -1.5583e-03, -7.2718e-04, -6.5879e-04, -1.2431e-03, -1.5346e-03,\n",
       "                        4.3564e-04, -1.4836e-03, -1.3463e-03, -1.5140e-03, -1.5261e-03,\n",
       "                       -1.5839e-03,  1.3572e-03, -1.5413e-03, -1.4930e-03,  1.5714e-03,\n",
       "                       -9.5599e-04, -1.3504e-03,  1.5708e-03,  1.4399e-03, -1.1622e-03,\n",
       "                        1.0828e-03, -1.2146e-03,  1.4793e-03, -1.4516e-03,  1.5802e-03,\n",
       "                       -1.1272e-03,  1.5266e-03,  1.2618e-03, -1.3969e-03,  1.1253e-03,\n",
       "                        1.2668e-03,  7.5012e-04, -1.6089e-03,  1.2978e-03,  1.3674e-03,\n",
       "                       -1.3952e-03,  1.6306e-03, -1.5530e-03, -1.5982e-03, -1.6634e-03,\n",
       "                       -1.5726e-03, -1.4616e-03, -1.4111e-03,  1.5033e-03, -1.4957e-03,\n",
       "                       -1.4269e-03, -1.3186e-03,  1.2470e-03, -1.5001e-03,  1.3526e-03,\n",
       "                       -5.2778e-04,  1.5888e-03,  1.4270e-03,  1.3854e-03,  1.5620e-03,\n",
       "                       -1.4486e-03,  1.5187e-03, -1.4123e-03, -1.6288e-03,  1.4406e-03,\n",
       "                       -5.2143e-04, -1.2575e-03,  1.5776e-03,  1.3588e-03,  1.5641e-03,\n",
       "                        1.0062e-03, -8.1852e-04,  1.1981e-03,  1.2450e-03, -1.5093e-03,\n",
       "                       -1.5667e-03, -1.5215e-03, -1.0615e-03,  1.4461e-03, -1.1749e-03,\n",
       "                        1.3207e-03,  1.5451e-03, -9.9001e-04, -1.3334e-03, -1.2452e-03,\n",
       "                        1.5058e-03, -1.4487e-03,  1.0677e-03, -1.5625e-03,  1.2586e-03,\n",
       "                        9.0965e-04, -1.2674e-03,  8.4262e-04,  1.5619e-03, -1.4225e-03,\n",
       "                       -1.5413e-03, -1.3853e-03, -1.3958e-03,  1.0314e-03, -1.5590e-03,\n",
       "                        1.5678e-03,  1.5081e-04, -1.5770e-03, -5.3977e-04, -1.4180e-03,\n",
       "                        1.3738e-03,  1.2984e-03, -6.0171e-04, -1.1957e-03,  1.3633e-03,\n",
       "                       -1.5546e-03,  1.4629e-03,  1.4673e-03,  1.4412e-03, -1.5154e-03,\n",
       "                        1.6778e-03, -1.3968e-03, -1.4586e-03, -1.4876e-03, -1.1080e-03,\n",
       "                       -8.7903e-04, -3.5925e-04,  1.4195e-03,  1.4919e-03,  1.5250e-03,\n",
       "                       -1.4565e-03, -8.6752e-04, -5.6396e-04,  1.4902e-03,  1.5015e-03,\n",
       "                        1.2134e-03, -9.5466e-04, -1.5233e-03,  2.2305e-05,  1.2830e-03,\n",
       "                       -1.5892e-03,  1.2994e-03, -1.0396e-03,  1.5139e-03, -1.3267e-03,\n",
       "                        1.1460e-03, -1.4912e-03,  1.3724e-03,  5.5492e-04,  1.4357e-03,\n",
       "                        1.3800e-03, -8.2546e-04, -1.5211e-03,  1.2468e-03, -1.4440e-03,\n",
       "                       -1.3549e-03, -1.0008e-03, -1.5558e-03, -1.4857e-03,  1.3140e-03,\n",
       "                        1.4950e-03, -1.2678e-03, -1.4910e-03, -1.6274e-03, -1.3952e-04,\n",
       "                       -1.5253e-03, -1.2112e-03, -1.2255e-03, -4.2717e-04, -3.2231e-05,\n",
       "                       -1.5948e-03, -1.4663e-03, -1.2660e-03,  1.5405e-03, -1.2072e-03,\n",
       "                       -1.0904e-03,  1.5512e-03, -1.5870e-03,  1.5554e-03, -1.1512e-03,\n",
       "                        1.5849e-03, -1.2971e-03, -1.1670e-03,  1.4291e-03, -1.5487e-03,\n",
       "                        1.5413e-03, -7.4094e-05, -9.6070e-04,  1.5104e-03,  8.2726e-04,\n",
       "                       -1.4574e-03,  1.4415e-03,  1.3588e-03,  3.0356e-04,  1.1491e-03,\n",
       "                        1.5739e-03,  1.4997e-03, -1.5462e-03, -1.3638e-03,  1.5014e-04,\n",
       "                       -1.3602e-03,  1.5123e-03,  1.4216e-03, -1.3518e-03,  1.4674e-03,\n",
       "                       -1.5125e-03,  9.9570e-04, -1.4999e-03, -7.7208e-04, -1.5210e-03,\n",
       "                       -1.3801e-03,  1.4742e-03, -1.5407e-03,  1.4142e-03, -1.5724e-03,\n",
       "                        9.7879e-05, -1.5794e-03, -1.3421e-03, -1.3576e-03,  1.5120e-03,\n",
       "                       -1.5973e-03, -1.3202e-03, -1.2599e-03,  1.4034e-03,  1.5668e-03,\n",
       "                       -1.3820e-03,  1.4713e-03,  1.0920e-03, -1.5532e-03,  1.5476e-03,\n",
       "                       -1.5689e-03, -1.5316e-03,  5.3865e-04,  1.6017e-03,  1.2057e-03,\n",
       "                        1.3329e-03,  1.3696e-03,  1.6305e-03, -1.6597e-03, -1.5987e-03,\n",
       "                       -1.4865e-03,  1.4290e-03,  1.5364e-03, -1.2538e-03,  4.0096e-04,\n",
       "                       -1.3758e-03,  1.4278e-03, -1.0102e-03,  1.3650e-03, -1.3288e-03,\n",
       "                       -1.2774e-03, -7.6622e-04, -1.5435e-03, -1.3740e-03,  1.2025e-03,\n",
       "                        1.4853e-03, -1.5425e-03, -1.6033e-03,  1.3068e-03,  1.4785e-03,\n",
       "                        1.5257e-03,  1.3899e-03, -1.2173e-03, -1.4340e-03,  1.4723e-03,\n",
       "                        1.4434e-03,  9.5180e-05, -1.0960e-03, -1.3238e-03,  8.8130e-04,\n",
       "                       -1.6768e-03,  1.2135e-03, -3.0921e-04, -1.4605e-03, -9.4589e-04,\n",
       "                        1.5669e-03, -1.2219e-03])),\n",
       "              ('transformer_encoder.layers.0.pre_linear1.weight',\n",
       "               tensor([[-0.0033],\n",
       "                       [ 0.5427],\n",
       "                       [ 0.6786],\n",
       "                       [-0.5472],\n",
       "                       [-0.7870],\n",
       "                       [ 0.4772],\n",
       "                       [-0.7058],\n",
       "                       [-0.2224],\n",
       "                       [ 0.6450],\n",
       "                       [ 0.7747],\n",
       "                       [-0.7350],\n",
       "                       [ 0.9419],\n",
       "                       [-0.7490],\n",
       "                       [-0.6353],\n",
       "                       [ 0.0987],\n",
       "                       [ 0.6047],\n",
       "                       [ 0.2588],\n",
       "                       [ 0.8932],\n",
       "                       [ 0.5623],\n",
       "                       [-0.4180],\n",
       "                       [-0.8475],\n",
       "                       [-0.5592],\n",
       "                       [-0.5139],\n",
       "                       [-0.7393],\n",
       "                       [ 0.3469],\n",
       "                       [ 0.1072],\n",
       "                       [ 0.3759],\n",
       "                       [-0.9653],\n",
       "                       [ 0.7367],\n",
       "                       [ 0.1209],\n",
       "                       [ 0.2187],\n",
       "                       [-0.9186],\n",
       "                       [ 0.6555],\n",
       "                       [-0.9449],\n",
       "                       [-0.2413],\n",
       "                       [-0.3386],\n",
       "                       [ 0.2608],\n",
       "                       [ 0.0219],\n",
       "                       [ 0.0611],\n",
       "                       [ 0.0895],\n",
       "                       [-0.8027],\n",
       "                       [ 0.9215],\n",
       "                       [-0.8990],\n",
       "                       [-0.5550],\n",
       "                       [ 0.0837],\n",
       "                       [-0.2078],\n",
       "                       [-0.0222],\n",
       "                       [ 0.6171],\n",
       "                       [ 0.9525],\n",
       "                       [ 0.0570],\n",
       "                       [ 0.0202],\n",
       "                       [ 0.7663],\n",
       "                       [-0.7880],\n",
       "                       [ 0.4600],\n",
       "                       [-0.1240],\n",
       "                       [ 0.0377],\n",
       "                       [ 0.7993],\n",
       "                       [ 0.0276],\n",
       "                       [ 0.0280],\n",
       "                       [ 0.9165],\n",
       "                       [ 0.7955],\n",
       "                       [ 0.6265],\n",
       "                       [-0.5134],\n",
       "                       [-0.0816],\n",
       "                       [-0.5127],\n",
       "                       [-0.4295],\n",
       "                       [-0.5486],\n",
       "                       [ 0.6302],\n",
       "                       [ 0.0381],\n",
       "                       [-0.9023],\n",
       "                       [ 0.3585],\n",
       "                       [ 0.6311],\n",
       "                       [-0.0823],\n",
       "                       [ 0.0567],\n",
       "                       [ 0.8371],\n",
       "                       [ 0.3441],\n",
       "                       [ 0.8558],\n",
       "                       [ 0.8809],\n",
       "                       [-0.6454],\n",
       "                       [-0.7122],\n",
       "                       [-0.9608],\n",
       "                       [ 0.7892],\n",
       "                       [-0.4917],\n",
       "                       [-0.5478],\n",
       "                       [-0.6300],\n",
       "                       [ 0.4347],\n",
       "                       [ 0.7168],\n",
       "                       [-0.5426],\n",
       "                       [-0.0302],\n",
       "                       [-0.2253],\n",
       "                       [-0.6726],\n",
       "                       [-0.6449],\n",
       "                       [ 0.1933],\n",
       "                       [ 0.6989],\n",
       "                       [ 0.9372],\n",
       "                       [-0.3892],\n",
       "                       [-0.4889],\n",
       "                       [-0.4802],\n",
       "                       [-0.8454],\n",
       "                       [-0.4529]])),\n",
       "              ('transformer_encoder.layers.0.pre_linear1.bias',\n",
       "               tensor([-0.2751, -0.8180,  0.9287, -0.6186,  0.8065, -0.8267, -0.7049, -0.2539,\n",
       "                       -0.6329, -0.2999,  0.6367,  0.7069, -0.4265,  0.0036, -0.9227, -0.4507,\n",
       "                       -0.4480,  0.2294, -0.5977,  0.1434, -0.7270,  0.3118, -0.4012,  0.4885,\n",
       "                        0.2046,  0.8837,  0.0867,  0.7196, -0.5535,  0.5117,  0.5943,  0.7800,\n",
       "                       -0.0991,  0.8575,  0.0989,  0.6919,  0.3140, -0.4234,  0.6130, -0.2598,\n",
       "                       -0.2291, -0.6157, -0.4928,  0.2892,  0.8567,  0.3206, -0.5259,  0.3883,\n",
       "                       -0.5841,  0.2216, -0.7352, -0.0273, -0.0124,  0.5340, -0.8870, -0.8427,\n",
       "                       -0.7199,  0.0727,  0.9606,  0.8952, -0.6521, -0.4915, -0.0032, -0.5818,\n",
       "                        0.0679,  0.5056,  0.1256, -0.6041,  0.4440,  0.4148, -0.0106,  0.4200,\n",
       "                       -0.0597,  0.3955,  0.6332,  0.4581,  0.8584, -0.6861, -0.3021, -0.6452,\n",
       "                        0.0556, -0.6371, -0.1231,  0.4047,  0.8681,  0.9983, -0.3635,  0.7638,\n",
       "                        0.1388, -0.7080,  0.2691,  0.9640,  0.2391,  0.7689,  0.1896,  0.2719,\n",
       "                        0.6953, -0.5175, -0.8567,  0.3788])),\n",
       "              ('transformer_encoder.layers.0.inter_feature_attn.in_proj_weight',\n",
       "               tensor([[ 0.0876,  0.0457, -0.0426,  ...,  0.0865,  0.0605,  0.0723],\n",
       "                       [-0.0601,  0.0428, -0.0845,  ..., -0.0908, -0.0151,  0.0190],\n",
       "                       [ 0.0548, -0.0510, -0.0828,  ..., -0.0018,  0.1080,  0.0156],\n",
       "                       ...,\n",
       "                       [ 0.0352,  0.0340, -0.0236,  ...,  0.0344, -0.0907, -0.0970],\n",
       "                       [ 0.0285,  0.0092, -0.0018,  ..., -0.0488, -0.1118, -0.0081],\n",
       "                       [ 0.0432,  0.1193,  0.0107,  ...,  0.0989,  0.0347, -0.1149]])),\n",
       "              ('transformer_encoder.layers.0.inter_feature_attn.in_proj_bias',\n",
       "               tensor([-1.1786e-04, -9.2333e-05,  1.1524e-04, -1.1762e-04,  1.1652e-04,\n",
       "                        1.1737e-04,  1.1688e-04,  1.1637e-04, -1.1776e-04, -1.1751e-04,\n",
       "                        1.1747e-04, -1.1800e-04,  1.1708e-04, -1.1766e-04, -8.6843e-05,\n",
       "                        1.1572e-04,  1.1795e-04, -1.1780e-04,  1.1811e-04,  1.1685e-04,\n",
       "                       -1.1690e-04, -1.1648e-04,  1.1745e-04,  1.1763e-04,  1.1636e-04,\n",
       "                       -2.1392e-04, -8.1180e-05,  2.1325e-04, -2.1356e-04,  2.1608e-04,\n",
       "                        2.1463e-04,  2.1231e-04,  2.1382e-04, -2.1356e-04,  2.3119e-04,\n",
       "                       -2.1047e-04, -2.0801e-04,  2.1233e-04, -2.1056e-04, -2.0458e-04,\n",
       "                       -1.9358e-04, -2.1489e-04,  2.1340e-04, -2.1079e-04,  2.0965e-04,\n",
       "                        2.1305e-04,  2.1328e-04,  2.1231e-04,  2.1461e-04,  2.0619e-04,\n",
       "                        2.4388e-04, -2.4625e-04,  2.4253e-04, -2.4549e-04,  2.4589e-04,\n",
       "                        2.3731e-04,  2.4410e-04, -2.5084e-04,  2.4377e-04, -2.4553e-04,\n",
       "                       -2.4188e-04,  2.2927e-04,  2.4499e-04,  2.4227e-04,  2.4334e-04,\n",
       "                       -2.4621e-04, -3.3862e-05,  2.3505e-04,  1.4424e-04, -2.3566e-04,\n",
       "                        2.4112e-04,  2.4344e-04, -2.4087e-04,  2.3791e-04, -2.4273e-04,\n",
       "                       -9.4785e-05,  9.7521e-05,  9.5559e-05, -9.5965e-05,  9.6081e-05,\n",
       "                        9.2449e-05, -9.6322e-05,  9.7398e-05, -9.7940e-05, -9.2458e-05,\n",
       "                        9.5594e-05,  9.4517e-05, -9.6420e-05, -9.6275e-05,  9.7061e-05,\n",
       "                        9.7367e-05, -9.7203e-05,  9.8788e-05,  9.8741e-05, -9.6159e-05,\n",
       "                        9.7244e-05, -9.7818e-05, -9.6953e-05,  8.3711e-05, -9.4989e-05,\n",
       "                       -2.8504e-09,  2.4750e-09, -1.0976e-09, -1.2613e-09, -8.8705e-13,\n",
       "                       -1.9412e-09, -8.2194e-10, -2.7303e-10,  1.7803e-09, -1.4273e-09,\n",
       "                       -5.3666e-10, -1.3614e-09, -1.4391e-09, -2.8419e-09,  4.2468e-10,\n",
       "                        5.9833e-10,  9.0045e-10, -1.8070e-09,  2.3247e-09, -1.2522e-09,\n",
       "                        1.0028e-09,  8.7975e-11, -2.9071e-09, -1.6263e-10, -1.7249e-09,\n",
       "                       -3.6669e-10,  1.1123e-09,  4.2207e-09, -5.3907e-09, -1.6462e-09,\n",
       "                       -1.5538e-09,  2.6001e-09,  4.2213e-10,  1.6462e-09, -4.2065e-09,\n",
       "                       -2.5625e-09, -1.3099e-09,  5.4053e-09,  1.1425e-10,  1.7678e-09,\n",
       "                        8.8228e-11,  1.5825e-09,  3.0302e-09, -6.2900e-09,  4.2154e-09,\n",
       "                       -1.5628e-09,  2.0181e-09,  1.8225e-09, -3.5962e-09,  1.5037e-09,\n",
       "                       -5.3917e-10,  1.7042e-10, -3.1562e-10, -2.1916e-10,  8.2597e-10,\n",
       "                        7.8082e-11, -5.3178e-10, -1.0286e-09,  1.1623e-09, -3.5089e-10,\n",
       "                        6.4771e-10, -1.7534e-10, -1.6684e-09, -5.9859e-10, -2.5055e-10,\n",
       "                       -5.0259e-10,  2.9993e-10, -7.7170e-10,  1.3937e-11,  9.1522e-10,\n",
       "                       -2.6265e-10, -4.5652e-10,  3.1967e-10, -1.0635e-10,  6.6266e-10,\n",
       "                       -1.4162e-09, -1.8493e-10,  5.5961e-10,  9.1878e-10,  4.3129e-10,\n",
       "                        8.7842e-10, -4.9424e-10, -7.4573e-10,  3.6932e-10, -9.9918e-10,\n",
       "                        1.2944e-09,  2.1547e-09, -5.3498e-10,  3.9603e-10, -4.3807e-10,\n",
       "                       -2.6348e-09,  2.2413e-10, -2.4461e-09, -1.6087e-09, -3.1258e-10,\n",
       "                       -8.1802e-10,  2.4464e-10,  5.3744e-10,  9.4121e-10, -1.3511e-09,\n",
       "                        1.8552e-04, -6.5041e-05,  5.9038e-05,  6.5051e-05,  6.0900e-05,\n",
       "                        5.6832e-05, -8.7429e-05,  1.9488e-05,  1.2293e-04, -2.3443e-04,\n",
       "                        3.2091e-05,  1.2018e-05,  7.5172e-05,  9.6590e-05,  2.2946e-04,\n",
       "                       -7.1601e-06,  6.9229e-05,  1.0774e-04,  2.0635e-04, -5.1768e-05,\n",
       "                        5.1720e-05,  6.5104e-05, -1.3030e-04, -2.4097e-04,  1.3161e-04,\n",
       "                       -1.9398e-05,  5.0271e-06, -2.3869e-04, -3.3320e-05,  1.5425e-04,\n",
       "                       -6.6491e-05,  1.8685e-06, -1.8720e-04, -9.8949e-05, -1.4638e-04,\n",
       "                       -2.1233e-04,  4.6096e-05,  2.4553e-05,  7.0715e-05,  5.0332e-05,\n",
       "                       -1.9195e-04,  1.8835e-04, -4.7850e-05,  1.3921e-04,  8.1781e-05,\n",
       "                        9.3561e-05, -5.6553e-05, -4.5775e-05, -5.5487e-05,  1.2686e-04,\n",
       "                       -4.3517e-05,  7.8834e-05,  5.6260e-05,  1.4190e-04,  5.7101e-05,\n",
       "                       -7.1870e-05,  4.5959e-05,  8.9327e-05, -1.6783e-05, -1.3139e-04,\n",
       "                        9.1362e-05, -4.4762e-05,  1.2659e-04, -1.4531e-04, -1.1738e-04,\n",
       "                       -1.4823e-04,  4.6938e-05,  2.0947e-04,  3.4012e-05, -5.5702e-05,\n",
       "                        2.6377e-04, -1.2294e-04, -9.6278e-06, -1.6288e-04,  1.3116e-04,\n",
       "                        8.2206e-05, -5.7715e-05, -6.0293e-05,  1.9121e-04, -9.9326e-05,\n",
       "                        1.9265e-04,  5.6675e-05, -1.2165e-04, -6.2809e-05,  1.7832e-04,\n",
       "                        1.3867e-04, -1.0476e-04,  1.2903e-04, -2.2112e-04, -2.8039e-04,\n",
       "                        1.9906e-04,  1.7179e-04, -2.2469e-04,  8.3229e-05,  1.9173e-04,\n",
       "                       -1.5591e-04, -1.0425e-04,  3.8975e-05,  4.0651e-05,  2.7304e-04])),\n",
       "              ('transformer_encoder.layers.0.inter_feature_attn.out_proj.weight',\n",
       "               tensor([[-0.0225, -0.0359,  0.0973,  ...,  0.0361, -0.0180, -0.0061],\n",
       "                       [-0.0679,  0.0184,  0.0341,  ...,  0.0337,  0.0450, -0.0678],\n",
       "                       [-0.0550,  0.0387, -0.0578,  ...,  0.0040, -0.0384,  0.0822],\n",
       "                       ...,\n",
       "                       [ 0.0210, -0.0773,  0.0245,  ...,  0.0510, -0.0441,  0.0486],\n",
       "                       [-0.0763,  0.0956, -0.0445,  ..., -0.0739,  0.0636, -0.0820],\n",
       "                       [ 0.0969, -0.0787,  0.0879,  ...,  0.0275,  0.0443,  0.0106]])),\n",
       "              ('transformer_encoder.layers.0.inter_feature_attn.out_proj.bias',\n",
       "               tensor([ 8.3721e-05, -1.4188e-04, -8.7560e-05, -2.0197e-04, -1.1202e-04,\n",
       "                       -2.7715e-04,  3.6029e-05,  8.9368e-06, -3.3972e-05,  8.1764e-05,\n",
       "                       -9.9503e-05,  1.3628e-04, -8.4761e-05,  8.8389e-05, -4.6385e-05,\n",
       "                        8.2839e-05,  1.5823e-05, -7.4980e-06,  1.0519e-04, -1.9477e-05,\n",
       "                        1.5392e-04,  1.2544e-04,  1.9903e-04,  1.5838e-05,  1.9854e-06,\n",
       "                       -5.8499e-05,  1.5832e-04, -5.6514e-05, -1.0089e-04,  3.1270e-05,\n",
       "                       -6.3010e-05, -1.3184e-05, -1.7707e-04,  1.6974e-05, -9.0778e-05,\n",
       "                       -1.8643e-04,  1.6132e-05, -5.0695e-05, -6.2029e-05, -9.7682e-05,\n",
       "                       -1.0976e-04, -3.0118e-05, -2.0701e-04,  1.3442e-05, -1.2423e-04,\n",
       "                        2.1695e-04,  1.3606e-05,  8.6819e-05,  7.7622e-05, -4.0743e-05,\n",
       "                       -6.6282e-05,  8.1206e-05, -2.1365e-05,  2.8720e-05, -9.7235e-07,\n",
       "                       -4.0985e-05,  1.0532e-04,  1.3914e-04, -2.6705e-04,  1.3956e-05,\n",
       "                       -1.7008e-04, -5.6336e-05, -7.0405e-05,  1.3038e-04, -2.1383e-04,\n",
       "                        9.3949e-05,  1.1455e-06, -2.8134e-04,  9.3707e-05, -3.1486e-05,\n",
       "                        6.1624e-06,  1.5185e-04, -5.7219e-05, -1.6520e-04,  1.5911e-04,\n",
       "                        7.5776e-05,  1.4316e-04, -1.5036e-04,  7.5240e-05,  1.8080e-04,\n",
       "                        4.6802e-06,  1.1907e-05, -2.7831e-06, -2.6660e-05,  3.3648e-05,\n",
       "                        6.0935e-05,  4.4908e-05,  1.1238e-04, -2.0277e-05, -7.3401e-05,\n",
       "                        1.7546e-04, -1.9559e-04,  1.4537e-05,  1.6005e-04, -2.1943e-05,\n",
       "                        9.3661e-05, -5.3919e-05, -1.7388e-04, -4.8189e-05, -1.5306e-04])),\n",
       "              ('transformer_encoder.layers.0.pre_linear2.weight',\n",
       "               tensor([[ 0.0858, -0.0893, -0.0813,  ...,  0.0738, -0.0977,  0.0405],\n",
       "                       [-0.0797,  0.0438, -0.0888,  ...,  0.0091,  0.0969,  0.0207],\n",
       "                       [-0.0321, -0.0603,  0.0297,  ...,  0.0964, -0.0555, -0.0338],\n",
       "                       ...,\n",
       "                       [-0.0451,  0.0183,  0.0429,  ...,  0.0557, -0.0294,  0.0263],\n",
       "                       [-0.0712, -0.0966, -0.0633,  ...,  0.0617,  0.0985, -0.0838],\n",
       "                       [ 0.0684, -0.0537, -0.0229,  ..., -0.0451,  0.0677,  0.0835]])),\n",
       "              ('transformer_encoder.layers.0.pre_linear2.bias',\n",
       "               tensor([ 0.0788,  0.0898,  0.0931,  ..., -0.0140, -0.0816, -0.0838])),\n",
       "              ('transformer_encoder.layers.0.pre_linear3.weight',\n",
       "               tensor([[-0.0040, -0.0198,  0.0217,  ..., -0.0112,  0.0038, -0.0041]])),\n",
       "              ('transformer_encoder.layers.0.pre_linear3.bias',\n",
       "               tensor([0.0269])),\n",
       "              ('transformer_encoder.layers.0.pre_norm_.weight',\n",
       "               tensor([0.9995, 0.9993, 1.0000, 0.9993, 0.9996, 0.9993, 0.9992, 1.0000, 0.9995,\n",
       "                       0.9992, 0.9998, 0.9993, 0.9998, 0.9994, 0.9993, 0.9996, 1.0002, 0.9999,\n",
       "                       0.9994, 0.9994, 1.0000, 0.9993, 0.9996, 0.9996, 0.9998, 0.9995, 0.9993,\n",
       "                       0.9996, 0.9991, 0.9993, 0.9999, 1.0000, 0.9999, 0.9993, 1.0000, 0.9994,\n",
       "                       1.0002, 0.9993, 0.9993, 1.0003, 0.9993, 0.9993, 0.9994, 1.0000, 0.9999,\n",
       "                       0.9993, 1.0000, 0.9994, 0.9997, 0.9994, 0.9993, 0.9994, 0.9997, 0.9994,\n",
       "                       1.0002, 0.9999, 0.9997, 0.9995, 0.9998, 0.9996, 0.9993, 0.9996, 1.0002,\n",
       "                       0.9999, 0.9994, 0.9993, 1.0002, 0.9998, 0.9993, 0.9994, 0.9998, 1.0004,\n",
       "                       1.0000, 0.9996, 0.9996, 0.9994, 1.0002, 0.9999, 0.9998, 0.9999, 0.9995,\n",
       "                       0.9997, 0.9995, 0.9993, 0.9994, 0.9994, 1.0001, 0.9993, 0.9998, 0.9995,\n",
       "                       0.9999, 0.9994, 0.9991, 0.9997, 0.9999, 0.9996, 0.9995, 0.9992, 0.9995,\n",
       "                       0.9993])),\n",
       "              ('transformer_encoder.layers.0.pre_norm_.bias',\n",
       "               tensor([-5.0099e-04,  5.0708e-04, -4.1011e-04,  4.1625e-04, -4.8016e-05,\n",
       "                       -3.7290e-04,  5.4070e-04,  7.7470e-04,  5.5335e-04, -4.4863e-04,\n",
       "                       -5.0531e-04, -1.9231e-04,  2.2300e-04, -4.7025e-04,  2.4444e-04,\n",
       "                       -5.4381e-04, -5.4241e-04,  4.7363e-04,  2.7888e-04, -5.6027e-04,\n",
       "                        5.1795e-04, -3.4553e-04, -4.8246e-04,  5.1896e-04, -5.3348e-04,\n",
       "                       -6.5818e-04, -3.3036e-04, -5.8436e-04, -5.7011e-04,  3.6358e-04,\n",
       "                       -4.9113e-04,  7.6152e-04, -5.1821e-04,  5.7572e-04, -4.5149e-04,\n",
       "                        6.7980e-04,  5.2984e-04, -4.5049e-04,  5.7280e-04, -4.8412e-04,\n",
       "                        4.8958e-04, -3.7993e-04, -5.5638e-04, -8.3038e-04,  3.3286e-04,\n",
       "                       -4.7667e-04,  6.5699e-04, -3.8027e-04, -4.8417e-04,  3.8415e-04,\n",
       "                       -4.4771e-04,  1.3902e-04, -2.2344e-04,  6.1462e-04, -5.1056e-04,\n",
       "                        7.0737e-04,  5.2740e-04,  5.8148e-04,  1.6217e-04, -2.4117e-04,\n",
       "                       -4.5679e-04, -5.9147e-04,  6.9083e-04, -5.1273e-04,  4.0891e-04,\n",
       "                        5.6123e-04,  1.6005e-04, -4.7268e-04, -4.6414e-04, -5.3727e-04,\n",
       "                        4.9506e-04,  5.8989e-04,  6.3965e-04,  8.8878e-06,  5.3106e-04,\n",
       "                        4.7317e-04, -4.4651e-04, -7.7146e-04, -4.4862e-04,  5.3740e-04,\n",
       "                        4.4121e-04, -4.4510e-04, -6.0488e-04, -5.2950e-04,  4.5827e-04,\n",
       "                       -5.9685e-04, -4.0586e-04, -4.7813e-04, -6.0410e-04, -5.0438e-04,\n",
       "                        7.1786e-04, -9.2134e-05, -1.8597e-04,  2.8239e-04,  4.9212e-04,\n",
       "                        5.6883e-04,  4.6172e-04,  4.8795e-04, -6.7493e-04, -5.3139e-04])),\n",
       "              ('transformer_encoder.layers.0.pre_linear4.weight',\n",
       "               tensor([[-0.0177, -0.0579,  0.0688,  ...,  0.0696, -0.0894, -0.0952],\n",
       "                       [-0.0194,  0.0498,  0.0704,  ...,  0.0132,  0.0329, -0.0510],\n",
       "                       [-0.0824, -0.0694, -0.0660,  ..., -0.0840, -0.0351, -0.0143],\n",
       "                       ...,\n",
       "                       [-0.0011, -0.0084,  0.0303,  ..., -0.0011,  0.0311, -0.0545],\n",
       "                       [-0.0643,  0.0168,  0.0925,  ...,  0.0237, -0.0627, -0.0323],\n",
       "                       [ 0.0529,  0.0030,  0.0434,  ..., -0.0400,  0.0683, -0.0433]])),\n",
       "              ('transformer_encoder.layers.0.pre_linear4.bias',\n",
       "               tensor([ 0.0436, -0.0166,  0.0162,  ...,  0.0853, -0.0517,  0.0302])),\n",
       "              ('transformer_encoder.layers.0.pre_linear5.weight',\n",
       "               tensor([[-0.0001,  0.0078, -0.0130,  ...,  0.0240, -0.0057, -0.0060],\n",
       "                       [ 0.0158, -0.0112, -0.0045,  ...,  0.0019,  0.0158, -0.0012],\n",
       "                       [ 0.0159, -0.0282,  0.0219,  ...,  0.0234, -0.0248,  0.0166],\n",
       "                       ...,\n",
       "                       [-0.0034,  0.0001, -0.0175,  ...,  0.0013, -0.0028,  0.0022],\n",
       "                       [-0.0112, -0.0093, -0.0099,  ...,  0.0041, -0.0225, -0.0157],\n",
       "                       [ 0.0072,  0.0079,  0.0011,  ..., -0.0220, -0.0160, -0.0149]])),\n",
       "              ('transformer_encoder.layers.0.pre_linear5.bias',\n",
       "               tensor([ 2.8881e-02,  3.9519e-03,  4.0458e-03,  5.5129e-03, -9.1617e-03,\n",
       "                       -3.0982e-02, -1.9101e-02,  1.6161e-02, -2.1516e-02, -9.9106e-03,\n",
       "                       -3.1039e-02,  3.2172e-02,  1.2267e-02,  2.6984e-02, -1.5933e-02,\n",
       "                        4.5716e-03, -9.2038e-04,  2.2900e-02,  2.9780e-02, -1.6752e-03,\n",
       "                       -1.2116e-02, -1.1801e-02, -1.8213e-02,  7.1240e-03,  1.5434e-02,\n",
       "                       -1.5523e-02,  8.0160e-03,  8.8552e-03,  2.7276e-02,  7.4379e-03,\n",
       "                       -1.9989e-02, -7.4699e-03, -1.4029e-02, -7.9868e-03,  2.1624e-03,\n",
       "                        2.8737e-02, -9.8055e-03,  5.8573e-03,  2.5220e-02, -1.0872e-02,\n",
       "                        1.1899e-02, -1.2808e-02,  2.2405e-02,  5.1703e-03,  2.4401e-02,\n",
       "                        3.0343e-02,  9.3685e-03, -1.0803e-03, -1.5068e-02,  1.4211e-02,\n",
       "                        1.4623e-02, -5.6009e-04, -1.0802e-02,  7.2792e-03,  1.5682e-02,\n",
       "                        1.7923e-02,  2.4423e-02, -2.1471e-02,  2.7864e-02, -5.3665e-03,\n",
       "                        1.4538e-02,  1.4649e-02, -2.3103e-02, -7.3005e-03,  7.7708e-03,\n",
       "                        2.9645e-02,  2.3096e-02, -1.8952e-03,  1.0991e-02, -7.8554e-03,\n",
       "                       -6.3218e-03,  3.0430e-02,  8.5680e-03,  8.2037e-03, -2.4860e-02,\n",
       "                       -2.5129e-02,  2.3536e-03, -1.1567e-03,  3.2507e-04, -2.9351e-02,\n",
       "                        4.3577e-04,  8.2570e-03, -2.2630e-04, -2.2090e-02, -8.6135e-03,\n",
       "                       -3.1821e-02, -6.5726e-03,  3.1353e-02, -2.9902e-02, -1.6332e-02,\n",
       "                       -2.2261e-03, -2.6735e-02, -8.4227e-04,  7.0081e-03,  2.3711e-02,\n",
       "                        3.0416e-02,  3.1882e-02, -2.1670e-02,  2.5883e-02,  2.1726e-02,\n",
       "                        3.1889e-02,  1.3693e-02, -3.9530e-04,  2.1658e-02,  2.5913e-03,\n",
       "                        3.1301e-02, -7.2596e-03,  1.4786e-02,  3.0717e-02, -8.0461e-03,\n",
       "                        1.1293e-02,  3.1726e-02, -2.7676e-02, -1.2212e-02, -2.5830e-02,\n",
       "                        2.6519e-02,  1.8865e-02,  5.2266e-03,  1.8211e-02,  1.1628e-02,\n",
       "                       -1.9660e-02,  1.3064e-02,  1.7889e-02,  2.5025e-02, -2.9350e-02,\n",
       "                        9.7225e-03,  2.0656e-02,  1.1748e-02,  9.7210e-03,  2.8216e-02,\n",
       "                       -1.5491e-02, -2.3120e-02,  6.1319e-03,  2.2024e-03, -1.4141e-02,\n",
       "                        8.7423e-03, -1.0935e-02,  2.3982e-02, -2.2860e-03, -5.5594e-04,\n",
       "                       -1.9952e-02, -6.2756e-03, -2.8153e-03, -8.7354e-03,  2.4353e-02,\n",
       "                        2.3414e-02,  1.0866e-02,  1.6866e-03, -1.1560e-03,  2.5663e-02,\n",
       "                        2.2993e-02,  2.6019e-02,  2.7719e-02, -1.5886e-02, -1.0130e-02,\n",
       "                       -1.2831e-02,  2.3448e-02, -1.5497e-02,  1.6020e-02, -1.3302e-02,\n",
       "                        2.1392e-02,  2.5683e-02, -2.1046e-02,  2.1246e-02,  7.0017e-05,\n",
       "                        3.1610e-02, -6.4237e-03, -1.0225e-02, -8.5477e-03,  4.6271e-03,\n",
       "                       -7.3895e-03,  2.4568e-02,  3.5940e-03, -3.1132e-03, -3.0724e-02,\n",
       "                       -3.9526e-03, -1.3054e-02,  2.3428e-03,  2.4717e-02,  3.0635e-02,\n",
       "                       -1.7391e-02, -2.5073e-02, -2.2301e-02, -2.4101e-02,  3.1718e-02,\n",
       "                        3.1905e-02,  1.6810e-02, -1.0163e-02,  7.4053e-04, -1.8012e-02,\n",
       "                       -1.8579e-02,  1.7399e-02, -8.7757e-03, -1.6645e-03, -3.1668e-02,\n",
       "                       -2.5240e-02, -4.8544e-03, -2.4576e-02,  1.1744e-02,  5.9444e-03,\n",
       "                       -2.5610e-02,  9.5840e-03,  2.8878e-02,  2.9035e-02,  5.7319e-03,\n",
       "                        2.5225e-02,  2.4155e-02,  1.0613e-02,  1.2776e-02, -2.1604e-02,\n",
       "                       -1.2090e-02, -2.5583e-02,  2.4706e-02, -2.5966e-03,  2.1868e-02,\n",
       "                       -1.5959e-02,  3.7835e-04,  9.3616e-03,  5.1888e-03, -1.8890e-02,\n",
       "                        2.4362e-02, -3.1715e-02, -4.5783e-03, -1.5968e-02, -1.5690e-02,\n",
       "                        1.2855e-02, -1.3755e-02, -2.6676e-02,  2.0402e-02, -7.6618e-03,\n",
       "                       -6.7732e-03,  1.8518e-03, -9.6176e-03,  2.0927e-02, -2.8795e-02,\n",
       "                        1.6507e-02,  3.2125e-02, -1.9733e-02, -2.1207e-02,  3.1263e-02,\n",
       "                        1.9232e-03, -1.0068e-02,  2.5274e-02,  3.9776e-03, -2.6524e-02,\n",
       "                        9.8116e-03,  2.9241e-03, -2.1640e-02, -1.2266e-02,  1.0675e-02,\n",
       "                        1.3191e-03,  7.8945e-03, -1.4441e-02, -1.1964e-02,  1.9278e-02,\n",
       "                       -1.8759e-02,  2.2716e-02,  7.1110e-03, -2.2492e-02,  1.2501e-02,\n",
       "                        1.5707e-02, -6.7696e-03, -2.7801e-02,  2.1901e-02, -1.5138e-03,\n",
       "                       -3.7852e-03, -1.9857e-02, -1.9825e-02, -2.0310e-02, -4.2709e-04,\n",
       "                       -2.8364e-02,  2.3107e-02,  2.7431e-02, -6.5644e-03, -2.1304e-02,\n",
       "                        2.8372e-03,  1.0636e-02,  2.6338e-02,  3.0259e-02,  1.1689e-02,\n",
       "                        5.8645e-03, -6.3512e-03, -8.8272e-03,  2.6989e-02, -9.9804e-03,\n",
       "                        1.2915e-02, -1.6448e-02,  3.7594e-03,  3.1542e-02,  2.9999e-05,\n",
       "                       -1.8760e-02,  2.8138e-02,  1.8040e-02, -8.4315e-04,  2.7953e-02,\n",
       "                       -1.9570e-02, -2.6224e-02,  2.1947e-02,  2.2983e-02,  5.6034e-03,\n",
       "                       -2.7049e-02, -7.6850e-03,  2.0779e-02,  1.0136e-02, -1.0761e-02,\n",
       "                       -2.4053e-02, -1.8023e-02,  1.2065e-04, -6.7083e-03,  2.5130e-02,\n",
       "                        2.8811e-02, -1.0512e-02, -3.5248e-03, -1.4534e-02, -3.2761e-02,\n",
       "                       -1.3936e-02,  1.5197e-02,  7.9602e-03,  1.8486e-02, -2.0258e-02,\n",
       "                       -2.9701e-02,  1.2516e-02, -9.5185e-03,  5.5315e-04, -1.6251e-02,\n",
       "                        3.1175e-02,  2.0406e-02, -2.5692e-02,  2.2096e-02, -1.5800e-02,\n",
       "                        1.0952e-02,  8.3970e-03, -1.0726e-02,  2.8219e-03, -1.5814e-02,\n",
       "                       -2.5763e-02, -2.9089e-02, -2.9003e-02, -7.0363e-04, -2.5997e-03,\n",
       "                        4.7900e-04,  2.4774e-02, -1.8550e-02, -3.6761e-03,  2.6007e-02,\n",
       "                        2.4642e-02,  2.0798e-02, -1.0524e-02, -3.0931e-02,  1.6676e-02,\n",
       "                        7.3147e-03,  3.2281e-03,  2.8789e-02,  2.6143e-02, -4.2168e-03,\n",
       "                       -1.3536e-02, -5.4536e-03, -2.0544e-04,  1.7646e-03, -3.8936e-04,\n",
       "                       -1.0613e-02,  1.0937e-03, -1.9343e-03, -2.8679e-02,  2.3203e-02,\n",
       "                       -4.9278e-03,  2.2054e-03, -3.1459e-02, -6.6944e-03,  3.0905e-02,\n",
       "                       -2.5739e-02, -3.2655e-02,  2.7940e-02, -2.2927e-02,  2.8579e-02,\n",
       "                       -3.1535e-02, -2.8939e-02, -1.3924e-03, -2.5516e-02, -7.5235e-04,\n",
       "                       -4.3902e-03, -1.1422e-02,  2.1493e-02,  7.7561e-04,  6.3121e-03,\n",
       "                        1.9246e-02, -2.3346e-03,  8.4107e-03, -1.6946e-02, -5.3455e-03,\n",
       "                        4.8485e-03,  1.2396e-02,  6.2841e-03,  1.5074e-02,  7.3492e-03,\n",
       "                       -1.3949e-02, -1.4031e-02,  1.4413e-02, -6.0246e-03, -4.0770e-03,\n",
       "                        7.3265e-03, -7.3496e-03,  1.5020e-02, -2.2372e-03,  1.2344e-02,\n",
       "                        2.1718e-02, -2.3531e-02, -6.9491e-03,  3.2807e-02,  1.0540e-02,\n",
       "                        1.2049e-02, -2.8129e-02, -2.8292e-02,  1.2943e-02, -1.0416e-02,\n",
       "                        8.6239e-03, -2.1892e-02, -1.8798e-02,  7.2643e-03, -9.8504e-03,\n",
       "                       -1.4829e-02,  1.6737e-02, -2.9611e-02, -2.2182e-02, -8.6776e-03,\n",
       "                       -2.2634e-02,  1.3711e-03, -1.2441e-02, -7.9785e-05, -2.4020e-02,\n",
       "                       -4.1679e-03,  2.5001e-02,  5.2099e-03, -5.5236e-03,  9.1400e-03,\n",
       "                       -2.6560e-02,  1.9042e-02,  7.9264e-03,  5.7687e-03,  1.0387e-02,\n",
       "                       -8.3700e-03, -2.2008e-02, -4.3441e-03,  1.1962e-02, -1.4065e-02,\n",
       "                        2.8446e-02,  1.3961e-03, -1.2410e-02,  6.7058e-03,  2.1401e-02,\n",
       "                       -4.6401e-03,  1.6454e-02, -2.9216e-02,  1.2336e-04,  4.7058e-03,\n",
       "                       -1.7895e-02, -1.4644e-02, -8.1891e-03, -1.5075e-03,  2.9061e-02,\n",
       "                       -1.2913e-02,  1.9703e-02,  2.0401e-02,  6.2100e-03,  9.4800e-03,\n",
       "                       -2.9356e-02, -1.7653e-02,  2.1128e-02, -6.9256e-03,  1.5648e-03,\n",
       "                       -1.5442e-02, -1.0240e-02, -5.6009e-03, -7.7571e-03,  7.0042e-03,\n",
       "                       -8.6959e-04,  8.3166e-03,  2.9392e-02, -1.7014e-02, -2.8715e-03,\n",
       "                       -1.8447e-02,  2.5984e-02,  7.8406e-03, -1.5242e-02, -4.3327e-03,\n",
       "                        2.6595e-02, -1.8156e-02,  4.1694e-03, -3.1403e-02,  3.6809e-03,\n",
       "                        1.3624e-04, -5.6730e-03, -7.4528e-03, -1.0012e-02,  1.5974e-02,\n",
       "                        1.7709e-02,  3.1273e-02,  1.9317e-02,  1.4628e-02,  7.2922e-03,\n",
       "                        2.5550e-02, -2.3134e-02, -1.0051e-02,  2.8148e-02,  1.6755e-02,\n",
       "                       -3.1692e-02,  1.3365e-02,  6.4142e-03, -1.0212e-02,  1.7332e-02,\n",
       "                        2.9055e-02,  4.2127e-03])),\n",
       "              ('transformer_encoder.layers.0.linear1.weight',\n",
       "               tensor([[ 0.0083,  0.0400, -0.0158,  ..., -0.0195,  0.0033,  0.0342],\n",
       "                       [-0.0329, -0.0378,  0.0116,  ..., -0.0129,  0.0122, -0.0343],\n",
       "                       [ 0.0262, -0.0233, -0.0239,  ..., -0.0225,  0.0393,  0.0426],\n",
       "                       ...,\n",
       "                       [-0.0400,  0.0173,  0.0101,  ...,  0.0031,  0.0319, -0.0120],\n",
       "                       [-0.0402,  0.0139,  0.0454,  ..., -0.0313,  0.0040, -0.0285],\n",
       "                       [-0.0134,  0.0252, -0.0311,  ...,  0.0348, -0.0356, -0.0357]])),\n",
       "              ('transformer_encoder.layers.0.linear1.bias',\n",
       "               tensor([ 0.0292, -0.0219,  0.0262,  ...,  0.0072, -0.0279,  0.0259])),\n",
       "              ('transformer_encoder.layers.0.linear2.weight',\n",
       "               tensor([[-0.0007, -0.0010,  0.0008,  ...,  0.0010, -0.0011, -0.0005],\n",
       "                       [ 0.0008,  0.0010, -0.0008,  ..., -0.0011,  0.0011,  0.0006],\n",
       "                       [-0.0007, -0.0008,  0.0008,  ...,  0.0007, -0.0009, -0.0004],\n",
       "                       ...,\n",
       "                       [ 0.0008,  0.0011, -0.0009,  ..., -0.0010,  0.0011,  0.0005],\n",
       "                       [-0.0011, -0.0012,  0.0010,  ...,  0.0010, -0.0012, -0.0009],\n",
       "                       [-0.0007, -0.0009,  0.0008,  ...,  0.0006, -0.0010, -0.0004]])),\n",
       "              ('transformer_encoder.layers.0.linear2.bias',\n",
       "               tensor([-4.8530e-04,  5.2687e-04, -4.2782e-04,  4.2871e-04, -9.2847e-05,\n",
       "                       -1.9872e-04,  5.0698e-04,  6.9616e-04,  5.6390e-04, -4.3856e-04,\n",
       "                       -5.1500e-04, -2.4410e-04,  1.0699e-04, -4.5794e-04,  2.7483e-04,\n",
       "                       -5.6086e-04, -4.4151e-04,  3.7635e-04,  3.3369e-04, -5.7320e-04,\n",
       "                        4.9538e-04, -2.9682e-04, -4.7877e-04,  5.3163e-04, -5.3503e-04,\n",
       "                       -6.2293e-04, -2.9226e-04, -6.0227e-04, -5.7272e-04,  3.5933e-04,\n",
       "                       -5.3484e-04,  7.3233e-04, -5.0984e-04,  5.6199e-04, -4.3602e-04,\n",
       "                        6.6796e-04,  5.1708e-04, -4.3675e-04,  5.8294e-04, -4.9198e-04,\n",
       "                        4.9851e-04, -3.7199e-04, -4.5945e-04, -8.6509e-04,  2.9667e-04,\n",
       "                       -4.7127e-04,  6.4599e-04, -3.7408e-04, -5.1795e-04,  4.0879e-04,\n",
       "                       -4.4555e-04,  1.2033e-04, -1.3829e-04,  6.3472e-04, -5.8157e-04,\n",
       "                        7.3125e-04,  5.2236e-04,  5.7501e-04,  2.8715e-04, -1.9648e-04,\n",
       "                       -4.5144e-04, -5.6951e-04,  6.8754e-04, -5.0327e-04,  3.9802e-04,\n",
       "                        5.5617e-04,  2.1150e-04, -4.7609e-04, -4.7289e-04, -5.3257e-04,\n",
       "                        4.9743e-04,  5.8259e-04,  6.3832e-04,  2.9426e-05,  5.8845e-04,\n",
       "                        4.7694e-04, -4.4024e-04, -7.7213e-04, -4.4988e-04,  5.5929e-04,\n",
       "                        4.4917e-04, -4.3139e-04, -5.5977e-04, -5.3611e-04,  4.0120e-04,\n",
       "                       -5.9764e-04, -3.5504e-04, -4.9632e-04, -5.6310e-04, -4.7660e-04,\n",
       "                        6.7471e-04, -1.4220e-04, -2.2929e-04,  2.7493e-04,  4.8071e-04,\n",
       "                        5.5773e-04,  4.5841e-04,  4.9343e-04, -6.8654e-04, -5.0827e-04])),\n",
       "              ('transformer_encoder.layers.0.norm1.weight',\n",
       "               tensor([1.0021, 1.0019, 1.0020, 1.0015, 1.0019, 1.0021, 1.0019, 1.0021, 1.0021,\n",
       "                       1.0020, 1.0021, 1.0020, 1.0021, 1.0019, 1.0016, 1.0020, 1.0012, 1.0021,\n",
       "                       1.0020, 1.0020, 1.0021, 1.0020, 1.0020, 1.0020, 1.0018, 1.0021, 1.0021,\n",
       "                       1.0020, 1.0020, 1.0020, 1.0021, 1.0021, 1.0021, 1.0020, 1.0020, 1.0021,\n",
       "                       1.0019, 1.0021, 1.0022, 1.0019, 1.0020, 1.0019, 1.0021, 1.0020, 1.0019,\n",
       "                       1.0019, 1.0020, 1.0020, 1.0015, 1.0021, 1.0021, 1.0020, 1.0020, 1.0019,\n",
       "                       1.0020, 1.0021, 1.0020, 1.0021, 1.0021, 1.0021, 1.0021, 1.0019, 1.0020,\n",
       "                       1.0019, 1.0019, 1.0019, 1.0022, 1.0020, 1.0021, 1.0018, 1.0017, 1.0020,\n",
       "                       1.0021, 1.0018, 1.0021, 1.0019, 1.0020, 1.0020, 1.0019, 1.0021, 1.0021,\n",
       "                       1.0021, 1.0021, 1.0020, 1.0019, 1.0020, 1.0020, 1.0021, 1.0019, 1.0020,\n",
       "                       1.0021, 1.0021, 1.0021, 1.0020, 1.0020, 1.0021, 1.0020, 1.0018, 1.0020,\n",
       "                       1.0021, 1.0017, 1.0021, 1.0020, 1.0021, 1.0021, 1.0019, 1.0020, 1.0020,\n",
       "                       1.0019, 1.0020, 1.0021, 1.0021, 1.0019, 1.0020, 1.0021, 1.0020, 1.0020,\n",
       "                       1.0011, 1.0020, 1.0021, 1.0019, 1.0021, 1.0020, 1.0019, 1.0020, 1.0022,\n",
       "                       1.0021, 1.0020, 1.0020, 1.0019, 1.0020, 1.0019, 1.0016, 1.0020, 1.0020,\n",
       "                       1.0020, 1.0022, 1.0021, 1.0021, 1.0021, 1.0020, 1.0013, 1.0017, 1.0019,\n",
       "                       1.0018, 1.0016, 1.0021, 1.0020, 1.0021, 1.0020, 1.0021, 1.0020, 1.0020,\n",
       "                       1.0021, 1.0020, 1.0020, 1.0020, 1.0021, 1.0020, 1.0020, 1.0021, 1.0021,\n",
       "                       1.0020, 1.0017, 1.0019, 1.0020, 1.0020, 1.0019, 1.0020, 1.0021, 1.0020,\n",
       "                       1.0019, 1.0019, 1.0020, 1.0020, 1.0014, 1.0020, 1.0021, 1.0022, 1.0021,\n",
       "                       1.0013, 1.0021, 1.0020, 1.0021, 1.0019, 1.0019, 1.0020, 1.0018, 1.0020,\n",
       "                       1.0021, 1.0019, 1.0020, 1.0020, 1.0020, 1.0019, 1.0020, 1.0019, 1.0022,\n",
       "                       1.0020, 1.0019, 1.0019, 1.0020, 1.0020, 1.0021, 1.0022, 1.0020, 1.0021,\n",
       "                       1.0020, 1.0020, 1.0020, 1.0020, 1.0021, 1.0021, 1.0019, 1.0019, 1.0020,\n",
       "                       1.0022, 1.0019, 1.0021, 1.0019, 1.0021, 1.0021, 1.0019, 1.0021, 1.0015,\n",
       "                       1.0020, 1.0018, 1.0020, 1.0020, 1.0015, 1.0020, 1.0020, 1.0020, 1.0020,\n",
       "                       1.0020, 1.0019, 1.0018, 1.0018, 1.0020, 1.0019, 1.0021, 1.0020, 1.0020,\n",
       "                       1.0020, 1.0021, 1.0021, 1.0020, 1.0019, 1.0020, 1.0021, 1.0016, 1.0021,\n",
       "                       1.0019, 1.0020, 1.0021, 1.0021, 1.0021, 1.0020, 1.0021, 1.0020, 1.0012,\n",
       "                       1.0021, 1.0021, 1.0021, 1.0021, 1.0021, 1.0020, 1.0021, 1.0021, 1.0021,\n",
       "                       1.0019, 1.0021, 1.0019, 1.0020, 1.0022, 1.0020, 1.0018, 1.0022, 1.0020,\n",
       "                       1.0021, 1.0020, 1.0022, 1.0021, 1.0022, 1.0021, 1.0021, 1.0020, 1.0020,\n",
       "                       1.0020, 1.0020, 1.0019, 1.0019, 1.0021, 1.0020, 1.0019, 1.0017, 1.0021,\n",
       "                       1.0021, 1.0020, 1.0021, 1.0021, 1.0020, 1.0020, 1.0021, 1.0020, 1.0020,\n",
       "                       1.0021, 1.0021, 1.0020, 1.0022, 1.0018, 1.0018, 1.0019, 1.0020, 1.0020,\n",
       "                       1.0021, 1.0021, 1.0019, 1.0020, 1.0019, 1.0020, 1.0021, 1.0019, 1.0021,\n",
       "                       1.0020, 1.0020, 1.0020, 1.0021, 1.0021, 1.0021, 1.0020, 1.0019, 1.0022,\n",
       "                       1.0020, 1.0020, 1.0020, 1.0020, 1.0019, 1.0019, 1.0021, 1.0021, 1.0016,\n",
       "                       1.0021, 1.0017, 1.0020, 1.0020, 1.0021, 1.0017, 1.0018, 1.0020, 1.0020,\n",
       "                       1.0020, 1.0022, 1.0019, 1.0021, 1.0021, 1.0020, 1.0020, 1.0020, 1.0018,\n",
       "                       1.0018, 1.0016, 1.0021, 1.0020, 1.0022, 1.0020, 1.0018, 1.0017, 1.0021,\n",
       "                       1.0017, 1.0019, 1.0019, 1.0022, 1.0017, 1.0019, 1.0021, 1.0021, 1.0020,\n",
       "                       1.0021, 1.0020, 1.0020, 1.0021, 1.0022, 1.0012, 1.0020, 1.0020, 1.0021,\n",
       "                       1.0020, 1.0020, 1.0022, 1.0019, 1.0016, 1.0022, 1.0021, 1.0020, 1.0020,\n",
       "                       1.0018, 1.0021, 1.0021, 1.0015, 1.0021, 1.0020, 1.0020, 1.0019, 1.0017,\n",
       "                       1.0022, 1.0020, 1.0019, 1.0020, 1.0020, 1.0018, 1.0021, 1.0022, 1.0021,\n",
       "                       1.0019, 1.0021, 1.0020, 1.0020, 1.0020, 1.0022, 1.0021, 1.0016, 1.0020,\n",
       "                       1.0021, 1.0018, 1.0021, 1.0020, 1.0021, 1.0017, 1.0019, 1.0021, 1.0020,\n",
       "                       1.0021, 1.0019, 1.0017, 1.0020, 1.0021, 1.0020, 1.0020, 1.0021, 1.0021,\n",
       "                       1.0019, 1.0020, 1.0017, 1.0021, 1.0020, 1.0020, 1.0020, 1.0021, 1.0021,\n",
       "                       1.0013, 1.0021, 1.0021, 1.0020, 1.0021, 1.0021, 1.0019, 1.0020, 1.0021,\n",
       "                       1.0022, 1.0019, 1.0020, 1.0019, 1.0021, 1.0020, 1.0021, 1.0021, 1.0018,\n",
       "                       1.0021, 1.0021, 1.0020, 1.0021, 1.0022, 1.0019, 1.0021, 1.0020, 1.0020,\n",
       "                       1.0020, 1.0020, 1.0018, 1.0021, 1.0021, 1.0019, 1.0020, 1.0019, 1.0021,\n",
       "                       1.0020, 1.0021, 1.0019, 1.0020, 1.0020, 1.0021, 1.0021, 1.0021, 1.0021,\n",
       "                       1.0020, 1.0019, 1.0019, 1.0021, 1.0020, 1.0021, 1.0018, 1.0021, 1.0018,\n",
       "                       1.0019, 1.0022, 1.0020, 1.0015, 1.0020, 1.0013, 1.0021, 1.0020])),\n",
       "              ('transformer_encoder.layers.0.norm1.bias',\n",
       "               tensor([-0.0020,  0.0020,  0.0017, -0.0021, -0.0019, -0.0021, -0.0019,  0.0020,\n",
       "                        0.0011, -0.0021, -0.0020,  0.0020,  0.0020,  0.0020, -0.0018,  0.0019,\n",
       "                        0.0012,  0.0021,  0.0019,  0.0020, -0.0021, -0.0020,  0.0014,  0.0019,\n",
       "                       -0.0020,  0.0019, -0.0020,  0.0022,  0.0019,  0.0020,  0.0020,  0.0020,\n",
       "                       -0.0021, -0.0019,  0.0021,  0.0020,  0.0021,  0.0020, -0.0019, -0.0019,\n",
       "                        0.0020, -0.0020, -0.0019,  0.0019, -0.0019,  0.0019, -0.0019, -0.0020,\n",
       "                       -0.0021,  0.0020,  0.0022, -0.0020,  0.0019, -0.0019, -0.0020, -0.0020,\n",
       "                        0.0020,  0.0021, -0.0020,  0.0021,  0.0020,  0.0019, -0.0020, -0.0019,\n",
       "                        0.0019,  0.0019, -0.0021, -0.0019, -0.0020, -0.0019, -0.0023,  0.0020,\n",
       "                        0.0020,  0.0019,  0.0020, -0.0019, -0.0020, -0.0019, -0.0019, -0.0022,\n",
       "                       -0.0020,  0.0020,  0.0020, -0.0019,  0.0021, -0.0019,  0.0021,  0.0020,\n",
       "                       -0.0021, -0.0019,  0.0020,  0.0021,  0.0020,  0.0020,  0.0019,  0.0020,\n",
       "                        0.0020, -0.0019,  0.0019,  0.0022,  0.0019,  0.0012, -0.0019,  0.0020,\n",
       "                       -0.0021,  0.0019,  0.0019,  0.0019,  0.0022, -0.0019, -0.0014,  0.0020,\n",
       "                       -0.0020, -0.0021, -0.0020, -0.0019, -0.0020,  0.0012,  0.0019, -0.0020,\n",
       "                        0.0019, -0.0020, -0.0020,  0.0019, -0.0020,  0.0021,  0.0020,  0.0020,\n",
       "                        0.0019, -0.0020,  0.0019,  0.0020,  0.0019,  0.0019,  0.0020, -0.0020,\n",
       "                       -0.0020, -0.0020,  0.0014,  0.0020, -0.0020,  0.0020, -0.0019,  0.0019,\n",
       "                       -0.0013,  0.0019, -0.0020,  0.0020, -0.0020, -0.0020,  0.0021, -0.0020,\n",
       "                       -0.0019, -0.0021, -0.0020, -0.0020,  0.0019, -0.0020, -0.0020, -0.0020,\n",
       "                        0.0019,  0.0021, -0.0019,  0.0018,  0.0019,  0.0020, -0.0019, -0.0019,\n",
       "                       -0.0019,  0.0020, -0.0020, -0.0019,  0.0019,  0.0019, -0.0020,  0.0008,\n",
       "                       -0.0020, -0.0019, -0.0021,  0.0021,  0.0018,  0.0020,  0.0019,  0.0020,\n",
       "                        0.0019,  0.0019,  0.0020, -0.0018, -0.0020, -0.0020,  0.0020,  0.0020,\n",
       "                        0.0019, -0.0019, -0.0019,  0.0020, -0.0021,  0.0021, -0.0019, -0.0019,\n",
       "                       -0.0020, -0.0019,  0.0019,  0.0020, -0.0022,  0.0019,  0.0021,  0.0020,\n",
       "                        0.0019, -0.0019, -0.0020, -0.0021,  0.0020,  0.0019,  0.0019,  0.0020,\n",
       "                       -0.0022, -0.0022,  0.0020,  0.0019,  0.0021, -0.0020, -0.0019,  0.0021,\n",
       "                        0.0020,  0.0020,  0.0019, -0.0019,  0.0020, -0.0014, -0.0019, -0.0020,\n",
       "                        0.0020,  0.0019, -0.0020, -0.0019,  0.0019, -0.0019,  0.0020,  0.0019,\n",
       "                        0.0020, -0.0020, -0.0016, -0.0020,  0.0019, -0.0020, -0.0016, -0.0020,\n",
       "                       -0.0020, -0.0020,  0.0019, -0.0020, -0.0019, -0.0019, -0.0020, -0.0020,\n",
       "                        0.0021, -0.0022, -0.0020,  0.0019,  0.0017, -0.0020,  0.0020,  0.0019,\n",
       "                       -0.0019,  0.0020, -0.0021,  0.0020, -0.0020,  0.0020, -0.0019,  0.0020,\n",
       "                        0.0019, -0.0019,  0.0021,  0.0020,  0.0019, -0.0021,  0.0020,  0.0020,\n",
       "                       -0.0020,  0.0020, -0.0020, -0.0021, -0.0021, -0.0020, -0.0020, -0.0020,\n",
       "                        0.0019, -0.0019, -0.0019, -0.0019,  0.0020, -0.0019,  0.0019, -0.0018,\n",
       "                        0.0020,  0.0020,  0.0019,  0.0021, -0.0020,  0.0020, -0.0019, -0.0020,\n",
       "                        0.0020, -0.0020, -0.0021,  0.0020,  0.0020,  0.0020,  0.0020, -0.0019,\n",
       "                        0.0019,  0.0020, -0.0019, -0.0020, -0.0021, -0.0019,  0.0019, -0.0019,\n",
       "                        0.0020,  0.0019, -0.0020, -0.0020, -0.0020,  0.0019, -0.0020,  0.0019,\n",
       "                       -0.0020,  0.0021,  0.0020, -0.0019,  0.0020,  0.0019, -0.0020, -0.0020,\n",
       "                       -0.0020, -0.0019,  0.0021, -0.0020,  0.0020,  0.0019, -0.0020, -0.0019,\n",
       "                       -0.0019,  0.0020,  0.0020, -0.0019, -0.0018,  0.0019, -0.0020,  0.0020,\n",
       "                        0.0021,  0.0019, -0.0021,  0.0021, -0.0020, -0.0019, -0.0019, -0.0019,\n",
       "                       -0.0019, -0.0018,  0.0022,  0.0019,  0.0020, -0.0020, -0.0018, -0.0018,\n",
       "                        0.0019,  0.0011,  0.0019, -0.0020, -0.0021,  0.0021,  0.0019, -0.0020,\n",
       "                        0.0020, -0.0021,  0.0020, -0.0020,  0.0021, -0.0020,  0.0021, -0.0020,\n",
       "                        0.0019,  0.0022, -0.0014, -0.0019,  0.0020, -0.0021, -0.0019, -0.0015,\n",
       "                       -0.0021, -0.0021,  0.0019,  0.0019, -0.0018, -0.0020, -0.0020,  0.0018,\n",
       "                       -0.0020, -0.0021, -0.0020, -0.0021,  0.0019, -0.0021, -0.0020, -0.0019,\n",
       "                        0.0019, -0.0019, -0.0019,  0.0020, -0.0021,  0.0019, -0.0022,  0.0019,\n",
       "                       -0.0020, -0.0020,  0.0019, -0.0021,  0.0020, -0.0021, -0.0020,  0.0021,\n",
       "                        0.0019, -0.0021,  0.0020,  0.0022,  0.0020,  0.0019,  0.0020,  0.0019,\n",
       "                       -0.0020, -0.0021,  0.0020, -0.0020,  0.0019,  0.0019, -0.0020,  0.0020,\n",
       "                       -0.0020,  0.0020, -0.0019, -0.0019, -0.0019, -0.0019,  0.0020, -0.0019,\n",
       "                        0.0020, -0.0020,  0.0020, -0.0020, -0.0020, -0.0020,  0.0021, -0.0020,\n",
       "                       -0.0019, -0.0020,  0.0020,  0.0021, -0.0019,  0.0021,  0.0019, -0.0020,\n",
       "                        0.0019, -0.0020, -0.0020,  0.0019,  0.0021,  0.0021,  0.0019,  0.0021,\n",
       "                        0.0021, -0.0021, -0.0020, -0.0020,  0.0020,  0.0019, -0.0020,  0.0020,\n",
       "                       -0.0020,  0.0020, -0.0019,  0.0020, -0.0019, -0.0021, -0.0014, -0.0020,\n",
       "                       -0.0019,  0.0020,  0.0019, -0.0021, -0.0020,  0.0020,  0.0020,  0.0019,\n",
       "                        0.0019, -0.0019, -0.0021,  0.0019,  0.0020, -0.0021, -0.0021, -0.0014,\n",
       "                        0.0020, -0.0022,  0.0020,  0.0018, -0.0019, -0.0021,  0.0019, -0.0020])),\n",
       "              ('transformer_encoder.layers.0.norm2.weight',\n",
       "               tensor([1.0002, 1.0000, 1.0001, 0.9995, 0.9995, 0.9993, 0.9994, 1.0004, 1.0005,\n",
       "                       0.9995, 0.9999, 0.9993, 0.9997, 0.9996, 0.9993, 1.0003, 1.0003, 0.9999,\n",
       "                       0.9994, 0.9997, 1.0002, 0.9993, 1.0000, 1.0004, 1.0008, 0.9999, 0.9993,\n",
       "                       1.0000, 0.9997, 0.9994, 1.0001, 1.0010, 1.0008, 1.0001, 1.0001, 1.0000,\n",
       "                       1.0006, 0.9995, 0.9997, 1.0006, 0.9999, 0.9993, 0.9994, 1.0009, 0.9999,\n",
       "                       0.9999, 1.0009, 0.9995, 0.9999, 0.9995, 0.9996, 0.9993, 0.9997, 1.0000,\n",
       "                       1.0003, 1.0005, 1.0000, 1.0006, 0.9999, 0.9995, 0.9994, 1.0006, 1.0009,\n",
       "                       1.0004, 0.9996, 1.0000, 1.0001, 1.0005, 0.9994, 0.9998, 1.0005, 1.0009,\n",
       "                       1.0004, 0.9996, 1.0000, 1.0000, 1.0002, 1.0007, 1.0000, 1.0005, 0.9997,\n",
       "                       1.0000, 0.9996, 0.9996, 0.9995, 1.0005, 1.0001, 0.9997, 1.0000, 0.9996,\n",
       "                       1.0003, 0.9994, 0.9991, 0.9996, 1.0001, 1.0008, 0.9999, 0.9999, 1.0001,\n",
       "                       0.9995])),\n",
       "              ('transformer_encoder.layers.0.norm2.bias',\n",
       "               tensor([-4.9533e-04,  5.4000e-04, -4.4019e-04,  4.3189e-04, -1.0264e-04,\n",
       "                       -2.1755e-04,  5.1379e-04,  7.4491e-04,  5.8188e-04, -4.4224e-04,\n",
       "                       -5.2812e-04, -2.3097e-04,  9.9780e-05, -4.6567e-04,  2.7153e-04,\n",
       "                       -5.7822e-04, -4.5841e-04,  3.8023e-04,  3.3423e-04, -5.9263e-04,\n",
       "                        5.0944e-04, -3.3315e-04, -4.9386e-04,  5.4695e-04, -5.4961e-04,\n",
       "                       -6.4275e-04, -2.9125e-04, -6.2039e-04, -5.9123e-04,  3.5628e-04,\n",
       "                       -5.4904e-04,  7.5847e-04, -5.2290e-04,  5.7825e-04, -4.4286e-04,\n",
       "                        6.8549e-04,  5.3096e-04, -4.4314e-04,  5.9324e-04, -5.0472e-04,\n",
       "                        5.1042e-04, -3.8249e-04, -4.6437e-04, -9.0998e-04,  2.9869e-04,\n",
       "                       -4.8065e-04,  6.6919e-04, -3.7425e-04, -5.3564e-04,  4.1410e-04,\n",
       "                       -4.5357e-04,  1.0829e-04, -1.1338e-04,  6.5239e-04, -6.0731e-04,\n",
       "                        7.6162e-04,  5.4392e-04,  5.9326e-04,  3.0972e-04, -1.8677e-04,\n",
       "                       -4.5619e-04, -5.8800e-04,  7.1415e-04, -5.1727e-04,  4.0082e-04,\n",
       "                        5.7501e-04,  2.0159e-04, -4.8593e-04, -4.7958e-04, -5.4952e-04,\n",
       "                        5.0737e-04,  6.0210e-04,  6.5949e-04,  6.1513e-06,  6.1006e-04,\n",
       "                        4.8769e-04, -4.4334e-04, -8.0796e-04, -4.5328e-04,  5.7172e-04,\n",
       "                        4.5579e-04, -4.3566e-04, -5.7001e-04, -5.5127e-04,  4.1567e-04,\n",
       "                       -6.1483e-04, -3.6384e-04, -5.0821e-04, -5.8402e-04, -4.8606e-04,\n",
       "                        7.0190e-04, -1.2489e-04, -2.4083e-04,  2.6619e-04,  4.8546e-04,\n",
       "                        5.7295e-04,  4.6810e-04,  5.0620e-04, -7.2066e-04, -5.3218e-04])),\n",
       "              ('transformer_encoder.layers.1.self_attn.in_proj_weight',\n",
       "               tensor([[ 0.0059, -0.0252,  0.0318,  ..., -0.0393, -0.0101,  0.0404],\n",
       "                       [ 0.0042, -0.0116, -0.0116,  ...,  0.0221, -0.0466,  0.0019],\n",
       "                       [ 0.0286, -0.0477,  0.0154,  ..., -0.0388,  0.0173, -0.0128],\n",
       "                       ...,\n",
       "                       [ 0.0372, -0.0170, -0.0118,  ...,  0.0070,  0.0369, -0.0318],\n",
       "                       [ 0.0364, -0.0367,  0.0263,  ..., -0.0246, -0.0333, -0.0216],\n",
       "                       [ 0.0444, -0.0539, -0.0332,  ...,  0.0351, -0.0110,  0.0356]])),\n",
       "              ('transformer_encoder.layers.1.self_attn.in_proj_bias',\n",
       "               tensor([-9.0794e-05, -9.2213e-04, -8.5924e-04,  ..., -1.5635e-03,\n",
       "                       -1.5758e-03,  1.5696e-03])),\n",
       "              ('transformer_encoder.layers.1.self_attn.out_proj.weight',\n",
       "               tensor([[ 0.0009,  0.0012,  0.0010,  ..., -0.0010, -0.0013,  0.0012],\n",
       "                       [-0.0017, -0.0018, -0.0016,  ...,  0.0016,  0.0017, -0.0017],\n",
       "                       [ 0.0016,  0.0017,  0.0014,  ..., -0.0015, -0.0016,  0.0015],\n",
       "                       ...,\n",
       "                       [-0.0017, -0.0017, -0.0015,  ...,  0.0015,  0.0017, -0.0016],\n",
       "                       [-0.0018, -0.0018, -0.0016,  ...,  0.0017,  0.0018, -0.0017],\n",
       "                       [ 0.0018,  0.0019,  0.0016,  ..., -0.0016, -0.0018,  0.0017]])),\n",
       "              ('transformer_encoder.layers.1.self_attn.out_proj.bias',\n",
       "               tensor([ 1.1278e-03, -1.4912e-03,  1.3538e-03,  9.3438e-04, -1.3489e-03,\n",
       "                       -1.5394e-03,  1.4761e-03,  1.3370e-03,  1.3923e-03,  1.3130e-03,\n",
       "                        1.4493e-03, -7.1626e-04, -5.3507e-04,  1.4946e-03,  1.4241e-03,\n",
       "                        1.4494e-03,  1.4168e-03, -1.5951e-03, -8.3776e-04, -1.2581e-03,\n",
       "                       -1.4441e-03, -1.1964e-03, -1.5910e-03, -1.1432e-03,  5.4888e-04,\n",
       "                       -1.5374e-03,  1.4659e-03, -1.4003e-03, -1.3815e-03,  1.4171e-03,\n",
       "                        1.4101e-03,  1.1135e-03, -1.4392e-03,  1.5484e-03, -4.3623e-04,\n",
       "                        1.2907e-03, -1.2195e-03, -2.4169e-04, -1.6204e-03, -1.3251e-03,\n",
       "                       -6.4166e-04,  4.1106e-04, -1.1266e-03,  1.3579e-03, -1.3943e-03,\n",
       "                       -1.2016e-03,  1.4156e-03, -1.5073e-03,  2.0981e-04,  1.1940e-03,\n",
       "                        1.3412e-03,  1.3355e-03, -1.6334e-03, -7.9407e-04,  1.4889e-03,\n",
       "                       -1.3202e-03, -1.1389e-03, -1.2576e-03,  1.4760e-03, -1.3951e-03,\n",
       "                       -1.4147e-03, -9.2772e-04,  1.4811e-03,  1.4722e-03, -1.3631e-03,\n",
       "                        1.2980e-03,  8.0692e-04, -1.5988e-03,  1.1237e-03, -1.3819e-03,\n",
       "                       -1.3016e-03,  1.2755e-03,  1.3737e-03, -9.7941e-04,  1.2696e-03,\n",
       "                        1.2930e-03, -1.4963e-03,  1.1241e-03,  1.4998e-03,  6.4126e-04,\n",
       "                       -1.3706e-03, -8.6397e-04,  1.0152e-03,  1.1437e-03, -1.5711e-03,\n",
       "                        5.1098e-04,  1.3043e-03,  1.4681e-03, -1.5596e-03, -7.8097e-04,\n",
       "                       -1.5206e-03,  1.3658e-03, -1.4730e-03,  1.3132e-03,  9.4634e-04,\n",
       "                        1.3087e-03,  1.4563e-03, -1.8020e-04, -1.1809e-03, -1.5731e-03,\n",
       "                        1.1073e-03, -1.5533e-03,  1.4437e-03, -1.4865e-03,  1.3644e-03,\n",
       "                       -1.2059e-03,  5.3353e-04,  1.4655e-03, -1.0127e-05,  9.4091e-05,\n",
       "                       -6.6480e-04,  1.3027e-03, -1.3689e-03,  1.2933e-03, -1.2346e-03,\n",
       "                        1.6363e-03,  1.7583e-03, -3.5701e-04,  1.4891e-03, -1.5211e-03,\n",
       "                        1.4672e-03, -1.5137e-03, -1.3701e-03,  1.4426e-03,  2.8730e-04,\n",
       "                       -1.0091e-03,  1.6204e-03,  6.3047e-04,  1.4340e-03, -1.5073e-03,\n",
       "                       -6.5800e-04,  1.6194e-03,  1.3768e-03,  1.0315e-03,  1.2653e-03,\n",
       "                       -1.2104e-03, -1.1519e-03, -1.3580e-03, -1.6440e-03,  1.2309e-03,\n",
       "                       -8.2673e-04,  1.2473e-03,  1.3666e-03, -1.3318e-03, -1.4035e-03,\n",
       "                       -1.4371e-03, -1.2451e-03,  1.3378e-03,  1.6208e-03,  1.5000e-03,\n",
       "                       -1.4414e-03,  1.3833e-03, -1.2926e-03, -1.4356e-03, -5.9367e-04,\n",
       "                       -1.5459e-03,  1.3790e-03,  1.2513e-03, -1.5715e-03,  1.5998e-03,\n",
       "                       -1.0300e-03,  1.4659e-03, -1.6061e-03, -1.6227e-03,  1.1351e-03,\n",
       "                        1.4657e-03,  1.5222e-03, -1.6144e-03, -1.5499e-03, -1.2023e-03,\n",
       "                       -8.7964e-04,  1.3452e-03, -3.9540e-05, -1.6225e-03, -1.6568e-03,\n",
       "                       -1.4889e-03, -1.2655e-03,  1.1974e-03, -1.3623e-03,  1.3390e-03,\n",
       "                       -1.4174e-03, -1.2625e-03, -1.5759e-03, -9.5945e-04, -1.5134e-03,\n",
       "                        1.0585e-03, -9.6443e-04,  1.0615e-03, -1.4573e-03, -1.5284e-03,\n",
       "                        1.6488e-03, -1.4761e-03,  1.3099e-03, -1.5047e-03,  1.3969e-03,\n",
       "                       -1.7545e-03, -1.1807e-03, -9.5517e-04,  5.1508e-04,  1.1085e-03,\n",
       "                        1.2725e-03, -6.0474e-04,  1.3263e-03, -1.0548e-03,  1.3205e-03,\n",
       "                        1.4588e-03,  1.6694e-04,  9.5196e-04, -1.3390e-03,  1.2950e-03,\n",
       "                        1.2618e-03,  5.0547e-04,  1.2678e-03, -1.3618e-03,  1.3430e-03,\n",
       "                        1.6262e-03,  1.1140e-03, -9.7098e-04,  7.9284e-04,  2.3240e-04,\n",
       "                       -1.5231e-03,  1.1402e-03, -1.4934e-03,  1.2432e-03, -1.3895e-03,\n",
       "                        1.5432e-03,  1.0648e-03,  1.3367e-03, -1.3047e-03, -1.3023e-03,\n",
       "                       -1.3729e-03, -1.3053e-03,  1.3876e-03, -2.5521e-04, -1.3212e-03,\n",
       "                       -1.3711e-03, -1.2634e-03, -6.1450e-04, -1.3306e-03, -1.6605e-03,\n",
       "                        3.8766e-04, -1.6230e-03,  5.8198e-04, -9.4763e-04, -1.4388e-03,\n",
       "                        1.2241e-03,  5.7851e-04,  1.3853e-03, -1.5184e-03, -5.2094e-04,\n",
       "                        1.5849e-03,  1.4506e-03, -1.3385e-03,  1.4924e-03,  6.7600e-04,\n",
       "                       -1.2776e-03, -1.4417e-03, -1.1513e-03,  1.4215e-03,  1.5549e-03,\n",
       "                        1.4803e-03, -1.5103e-03,  8.7192e-04,  1.3728e-03,  9.8084e-04,\n",
       "                       -1.5653e-03, -6.3497e-04,  1.2275e-03, -1.4534e-03,  1.4311e-03,\n",
       "                       -1.3900e-03,  1.3298e-03, -3.4736e-04,  7.2457e-04, -1.5369e-03,\n",
       "                        6.6140e-04, -1.3128e-03, -1.4918e-03, -1.3081e-03, -1.4371e-03,\n",
       "                        1.2702e-03,  1.1787e-03,  1.2967e-03,  3.1360e-04,  1.5191e-03,\n",
       "                       -1.2151e-03, -1.5920e-03,  1.4875e-03, -1.6164e-03,  6.9267e-04,\n",
       "                       -5.4570e-04,  1.4008e-03, -1.4777e-03, -1.2598e-03,  1.3548e-03,\n",
       "                        1.2648e-03,  1.3269e-03,  3.0940e-04, -1.1734e-03,  1.4354e-03,\n",
       "                        1.5660e-03,  1.4509e-03,  1.4045e-03,  1.2349e-03,  1.5374e-03,\n",
       "                        1.3559e-03,  1.4591e-03, -1.5511e-03, -1.1125e-03,  1.0658e-03,\n",
       "                        1.3155e-03, -1.4349e-03,  1.1703e-04,  1.5421e-03,  9.8989e-04,\n",
       "                        1.5442e-03, -1.1712e-03,  1.4525e-03,  1.0935e-03, -1.1908e-03,\n",
       "                        1.5952e-03,  1.4003e-03, -1.3644e-03,  1.2608e-03,  1.5511e-03,\n",
       "                        1.4058e-03, -1.4387e-03,  7.3037e-04,  1.5452e-03, -1.2515e-03,\n",
       "                        6.2525e-04, -1.5881e-03, -1.4996e-03,  1.4819e-03, -1.6691e-03,\n",
       "                        1.5450e-03, -1.0409e-03, -1.3950e-03, -1.6625e-03, -1.4285e-03,\n",
       "                       -1.4492e-03, -1.0749e-03, -1.1970e-03,  1.2632e-03,  1.1182e-03,\n",
       "                       -1.4020e-03, -1.3215e-03,  9.8755e-04,  1.3677e-03, -1.3352e-03,\n",
       "                        1.5591e-03, -1.3875e-03, -6.1465e-04,  1.4756e-03, -1.6065e-03,\n",
       "                       -1.2389e-03, -1.0407e-03, -1.1834e-03,  1.2945e-03, -9.0374e-04,\n",
       "                       -1.3876e-03,  1.3582e-03,  5.0704e-04, -1.4559e-03,  1.3109e-03,\n",
       "                       -1.2949e-03,  1.4835e-03, -1.0497e-03,  8.7538e-04, -1.4086e-03,\n",
       "                       -1.2511e-03, -1.4505e-03, -1.5146e-03, -6.7935e-04, -1.3819e-03,\n",
       "                        1.4871e-03,  8.5597e-04, -9.7217e-04,  8.6467e-04, -9.8283e-04,\n",
       "                        1.4025e-03, -1.1308e-03,  1.5508e-03, -1.5017e-03, -1.4015e-03,\n",
       "                        1.1067e-03,  1.0765e-03, -1.4042e-03,  1.4793e-03,  1.5614e-03,\n",
       "                       -4.2212e-04,  3.8490e-04,  1.3717e-03,  1.1786e-03, -1.3821e-03,\n",
       "                       -1.2905e-03, -1.4699e-03, -1.3770e-03, -1.3622e-03,  1.3364e-03,\n",
       "                        1.3106e-03,  1.1772e-03,  1.6053e-03, -1.2079e-03, -1.2312e-03,\n",
       "                       -1.5152e-03,  1.4430e-03, -1.4425e-03, -4.8507e-04,  1.5513e-03,\n",
       "                       -2.4808e-04, -1.4745e-03,  1.4341e-03,  1.4858e-03, -1.3851e-03,\n",
       "                        1.1150e-03, -1.2449e-03,  1.4900e-03, -4.1962e-04, -1.2827e-03,\n",
       "                       -1.0411e-03,  1.3010e-03,  1.2788e-03, -1.0578e-03,  1.3430e-03,\n",
       "                        1.4418e-03,  1.4782e-03,  7.7074e-04, -1.4349e-03, -1.5928e-03,\n",
       "                        1.3959e-03, -1.3430e-03,  1.4563e-03,  1.5250e-03, -1.3421e-03,\n",
       "                        1.2277e-03,  1.0636e-03,  1.4348e-03, -1.1320e-03, -8.7830e-04,\n",
       "                       -1.0067e-03,  1.4768e-03, -1.4177e-03,  1.4521e-03,  1.4458e-03,\n",
       "                       -1.2119e-03, -1.2201e-03,  1.6845e-03,  9.3250e-04, -1.4589e-03,\n",
       "                       -1.1881e-03, -1.1903e-03,  1.1787e-03,  1.6132e-03, -1.3047e-03,\n",
       "                        9.6337e-04,  1.1111e-03, -9.3888e-04, -1.1808e-03, -7.4432e-04,\n",
       "                       -1.4153e-03,  7.5035e-04,  6.8665e-04, -1.3908e-03, -1.2268e-03,\n",
       "                        1.5390e-03,  1.6031e-03,  1.3957e-03, -1.5218e-03, -1.2663e-03,\n",
       "                       -4.0087e-04, -1.4339e-03,  1.2929e-03, -1.3488e-03,  1.2551e-03,\n",
       "                       -5.9660e-05,  1.2229e-03, -7.0163e-04, -1.3510e-03,  1.1110e-03,\n",
       "                       -1.2538e-03,  1.2064e-03, -8.4349e-04, -1.2438e-03, -1.2639e-03,\n",
       "                        1.0897e-03, -1.5315e-03, -1.5311e-03, -1.4413e-03,  1.4946e-03,\n",
       "                       -1.4581e-03,  5.8303e-04, -1.6087e-03,  1.4675e-03,  1.4847e-03,\n",
       "                        1.1486e-03,  8.8091e-04, -1.3672e-03, -1.2405e-03,  1.2468e-03,\n",
       "                       -8.7221e-04,  1.1184e-03,  1.3066e-03,  1.3835e-03, -8.8672e-04,\n",
       "                        1.2145e-03,  1.3212e-03,  1.0562e-04, -7.9388e-04, -1.3984e-03,\n",
       "                       -1.5202e-03,  1.5177e-03])),\n",
       "              ('transformer_encoder.layers.1.pre_linear1.weight',\n",
       "               tensor([[ 0.1323],\n",
       "                       [-0.2377],\n",
       "                       [-0.3481],\n",
       "                       [-0.3742],\n",
       "                       [ 0.9630],\n",
       "                       [ 0.7386],\n",
       "                       [-0.9145],\n",
       "                       [-0.8208],\n",
       "                       [-0.7387],\n",
       "                       [-0.1476],\n",
       "                       [ 0.2498],\n",
       "                       [ 0.7021],\n",
       "                       [ 0.8689],\n",
       "                       [ 0.0425],\n",
       "                       [ 0.7099],\n",
       "                       [ 0.4872],\n",
       "                       [ 0.3205],\n",
       "                       [-0.1107],\n",
       "                       [ 0.6546],\n",
       "                       [-0.5833],\n",
       "                       [ 0.1143],\n",
       "                       [ 0.9319],\n",
       "                       [-0.3193],\n",
       "                       [-0.7872],\n",
       "                       [-0.3788],\n",
       "                       [ 0.0519],\n",
       "                       [-0.0986],\n",
       "                       [ 0.7783],\n",
       "                       [-0.5639],\n",
       "                       [-0.3577],\n",
       "                       [ 0.6134],\n",
       "                       [-0.8637],\n",
       "                       [-0.8080],\n",
       "                       [-0.9619],\n",
       "                       [-0.4195],\n",
       "                       [-0.6199],\n",
       "                       [-0.7791],\n",
       "                       [-0.9234],\n",
       "                       [-0.3539],\n",
       "                       [ 0.1284],\n",
       "                       [-0.8441],\n",
       "                       [-0.0745],\n",
       "                       [-0.7678],\n",
       "                       [ 0.0627],\n",
       "                       [-0.1271],\n",
       "                       [ 0.2350],\n",
       "                       [-0.0817],\n",
       "                       [-0.0709],\n",
       "                       [-0.6886],\n",
       "                       [-0.3614],\n",
       "                       [ 0.7256],\n",
       "                       [-0.3467],\n",
       "                       [-0.9258],\n",
       "                       [-0.7351],\n",
       "                       [-0.6389],\n",
       "                       [ 0.2282],\n",
       "                       [-0.7650],\n",
       "                       [-0.1792],\n",
       "                       [ 0.2477],\n",
       "                       [-0.5529],\n",
       "                       [-0.7068],\n",
       "                       [-0.0550],\n",
       "                       [ 0.1999],\n",
       "                       [ 0.5431],\n",
       "                       [ 0.7654],\n",
       "                       [ 0.4229],\n",
       "                       [-0.3902],\n",
       "                       [-0.4273],\n",
       "                       [-0.8052],\n",
       "                       [-0.2958],\n",
       "                       [ 0.9108],\n",
       "                       [ 0.3729],\n",
       "                       [ 0.9839],\n",
       "                       [ 0.9115],\n",
       "                       [-0.9552],\n",
       "                       [-0.2632],\n",
       "                       [-0.6498],\n",
       "                       [-0.0415],\n",
       "                       [-0.9586],\n",
       "                       [-0.4915],\n",
       "                       [-0.1367],\n",
       "                       [-0.3975],\n",
       "                       [ 0.6292],\n",
       "                       [ 0.3315],\n",
       "                       [ 0.6133],\n",
       "                       [ 0.0054],\n",
       "                       [ 0.5956],\n",
       "                       [-0.0976],\n",
       "                       [ 0.5375],\n",
       "                       [-0.9884],\n",
       "                       [ 0.4056],\n",
       "                       [ 0.9461],\n",
       "                       [-0.4715],\n",
       "                       [-0.4930],\n",
       "                       [ 0.1358],\n",
       "                       [ 0.6887],\n",
       "                       [ 0.0949],\n",
       "                       [ 0.8144],\n",
       "                       [ 0.3769],\n",
       "                       [ 0.0925]])),\n",
       "              ('transformer_encoder.layers.1.pre_linear1.bias',\n",
       "               tensor([-0.5249, -0.3640, -0.8934, -0.8795,  0.9855,  0.9372,  0.6888,  0.0060,\n",
       "                       -0.5095,  0.9995, -0.1301,  0.6599,  0.7216, -0.1400, -0.1506, -0.1199,\n",
       "                        0.6847, -0.6653, -0.9698, -0.1082,  0.3832,  0.1215, -0.3526,  0.3466,\n",
       "                       -0.3281,  0.0704,  0.6894,  0.7747, -0.0550,  0.0608, -0.0208,  0.0401,\n",
       "                        0.3304, -0.9223,  0.6269,  0.0420, -0.2687,  0.9478, -0.5577, -0.2498,\n",
       "                        0.1301, -0.7183,  0.5818,  0.8082,  0.0145, -0.2312,  0.3993, -0.4174,\n",
       "                       -0.1380, -0.8509, -0.7461,  0.1792, -0.4774,  0.3860, -0.6527,  0.8833,\n",
       "                       -0.8237, -0.3702,  0.5824,  0.2796,  0.5069, -0.4840,  0.6084, -0.2617,\n",
       "                        0.1861, -0.3162, -0.0833,  0.6676, -0.0327, -0.4344, -0.1694,  0.1774,\n",
       "                        0.7954, -0.2146,  0.4829, -0.9214, -0.5767, -0.6698,  0.6233,  0.6705,\n",
       "                       -0.2844, -0.3137, -0.5856, -0.2328,  0.6743,  0.2870,  0.7212, -0.1865,\n",
       "                       -0.4951, -0.7150,  0.9768,  0.5574, -0.9712,  0.9770, -0.5553, -0.2794,\n",
       "                        0.5569,  0.5401,  0.2489,  0.9774])),\n",
       "              ('transformer_encoder.layers.1.inter_feature_attn.in_proj_weight',\n",
       "               tensor([[-0.0582, -0.0793, -0.0070,  ...,  0.0926,  0.1123, -0.0457],\n",
       "                       [ 0.0706, -0.1182, -0.0893,  ...,  0.0729,  0.0794, -0.0937],\n",
       "                       [ 0.0130, -0.0229,  0.0506,  ..., -0.0933,  0.0612,  0.0131],\n",
       "                       ...,\n",
       "                       [ 0.0030,  0.0738,  0.0981,  ...,  0.0858,  0.0866, -0.0794],\n",
       "                       [-0.0455, -0.0973,  0.0319,  ..., -0.1075,  0.1042, -0.0297],\n",
       "                       [ 0.0520,  0.0811,  0.1104,  ..., -0.0620,  0.1088, -0.0513]])),\n",
       "              ('transformer_encoder.layers.1.inter_feature_attn.in_proj_bias',\n",
       "               tensor([ 8.1677e-05,  9.7145e-06,  4.4776e-05, -1.3559e-05,  7.6309e-05,\n",
       "                        1.0376e-04, -3.8210e-06, -5.8505e-05,  3.1723e-05,  7.5533e-05,\n",
       "                        1.3379e-04,  2.4673e-05,  1.6070e-04, -1.2258e-04,  6.7328e-05,\n",
       "                       -2.4260e-05, -1.2460e-04, -3.5031e-05, -1.5853e-04, -9.7135e-05,\n",
       "                        5.2096e-05,  9.8259e-05,  9.3190e-05,  5.6135e-05,  1.4913e-04,\n",
       "                       -4.5890e-04, -4.5055e-04,  4.6039e-04,  4.4489e-04, -4.7022e-04,\n",
       "                        4.5931e-04, -4.0332e-04, -4.3332e-04,  4.2377e-04,  4.6185e-04,\n",
       "                        4.4968e-04,  4.6543e-04, -4.2837e-04,  4.5267e-04, -4.5579e-04,\n",
       "                       -4.6563e-04,  4.6463e-04, -4.6765e-04,  4.6287e-04, -4.5068e-04,\n",
       "                       -4.6311e-04, -3.9876e-04,  4.6621e-04, -4.6867e-04,  4.2770e-04,\n",
       "                       -1.8281e-04,  1.2326e-04, -1.6106e-04, -1.6588e-04,  5.7330e-05,\n",
       "                        4.0917e-05,  1.1745e-04, -1.9907e-04,  1.7349e-05, -1.0043e-04,\n",
       "                       -1.3744e-04, -1.7608e-04, -2.1069e-04, -1.3979e-04,  2.1721e-04,\n",
       "                        4.7503e-05,  1.8345e-04,  5.1873e-05,  1.7077e-04, -1.9520e-04,\n",
       "                       -1.5541e-04,  2.2030e-04,  1.5346e-04,  1.3714e-04, -1.1558e-04,\n",
       "                       -2.2883e-05, -2.4238e-05,  1.9557e-05,  1.6522e-05, -2.1530e-05,\n",
       "                        6.9134e-06,  1.9814e-05, -2.2326e-05, -1.7364e-05, -3.0347e-06,\n",
       "                       -1.8246e-05, -1.8356e-05,  7.6378e-07, -2.0823e-05,  1.1220e-05,\n",
       "                       -2.0797e-05,  1.2941e-05, -1.8159e-05,  1.5017e-05, -2.4232e-05,\n",
       "                       -1.4489e-05,  1.4507e-05,  2.1145e-05,  1.5238e-05,  1.0630e-05,\n",
       "                       -6.5179e-10,  7.0206e-10, -1.9845e-10, -1.5149e-09,  4.7647e-10,\n",
       "                       -7.7780e-11, -2.6910e-10,  5.1811e-11, -5.7190e-11, -2.2368e-10,\n",
       "                        8.2908e-10,  1.8411e-11,  6.8381e-10,  1.1053e-10, -2.5082e-10,\n",
       "                       -5.5225e-10,  1.1672e-10,  6.1902e-11,  1.3232e-10, -2.3903e-10,\n",
       "                       -6.0190e-10, -3.7795e-10, -9.0908e-11,  6.5168e-10, -3.3680e-10,\n",
       "                        1.4051e-09, -1.6824e-09, -2.2635e-09, -1.3644e-09,  5.2359e-10,\n",
       "                       -8.9784e-10,  1.2516e-09, -4.0696e-10, -5.3568e-10, -1.7310e-09,\n",
       "                       -1.7113e-09,  8.1844e-10, -9.8125e-10, -5.7611e-10,  1.6680e-10,\n",
       "                        5.3811e-10, -6.4136e-10,  9.4440e-10, -3.1040e-10, -1.0632e-11,\n",
       "                        9.1897e-10, -1.7209e-09, -4.7390e-10,  6.3258e-10, -2.0109e-10,\n",
       "                       -5.5561e-11, -1.5733e-10, -1.1206e-10, -3.3537e-11, -4.7437e-11,\n",
       "                       -2.4800e-10,  7.4891e-11, -5.1288e-11,  5.4536e-12,  3.7847e-11,\n",
       "                       -2.2948e-11,  2.2190e-10,  6.5657e-11,  2.5263e-11, -1.3035e-10,\n",
       "                       -8.9697e-11,  7.8172e-11,  9.1535e-11,  8.4713e-11, -1.5266e-11,\n",
       "                       -1.0361e-10,  2.5389e-10, -8.2051e-12,  9.3955e-11, -5.7038e-11,\n",
       "                        8.8648e-10,  2.6979e-10, -4.9462e-10,  4.2838e-10,  2.8209e-10,\n",
       "                       -2.7778e-10,  3.4453e-10, -2.9314e-10,  2.5605e-09, -5.8537e-10,\n",
       "                       -1.4585e-10, -9.3968e-10, -4.9237e-10, -1.1781e-09, -7.1847e-10,\n",
       "                       -1.0396e-09, -1.5383e-09, -1.2823e-09, -5.0854e-10,  1.3425e-09,\n",
       "                        2.4568e-10,  5.4133e-10,  4.7981e-10, -1.8826e-09,  5.0339e-10,\n",
       "                       -1.2316e-04,  4.3587e-04, -4.1222e-05, -2.6206e-04, -6.5006e-04,\n",
       "                        3.5772e-04,  2.4377e-04, -3.2850e-04,  4.0911e-04, -2.1028e-04,\n",
       "                       -3.4147e-04,  3.1404e-04, -3.1714e-05, -2.0982e-04, -3.3315e-04,\n",
       "                       -1.6485e-04,  4.4047e-04,  4.1761e-04,  2.1365e-04, -2.6924e-04,\n",
       "                       -9.2156e-05, -3.2528e-04,  5.0782e-04, -4.5825e-04,  4.7265e-04,\n",
       "                        5.3107e-04, -4.0927e-04, -6.4292e-05, -5.0466e-05, -1.0813e-04,\n",
       "                        6.6633e-05, -2.1020e-04, -4.7814e-04,  3.1790e-04,  7.5614e-05,\n",
       "                       -5.2337e-05,  3.1237e-04,  3.2925e-04,  2.7766e-04, -3.6844e-04,\n",
       "                        3.7764e-04,  4.2391e-04,  4.7838e-04,  4.7916e-04,  4.9038e-05,\n",
       "                       -4.1784e-04,  4.3727e-04, -3.1017e-04, -3.3628e-04,  5.1372e-04,\n",
       "                       -1.5554e-04,  4.1305e-04,  2.0369e-04,  3.1575e-04, -3.7864e-04,\n",
       "                        4.1108e-04, -2.1114e-04,  3.7526e-04,  7.3788e-05,  2.9743e-04,\n",
       "                        3.9686e-04, -4.1366e-04, -2.7939e-04, -5.7605e-04, -4.6626e-04,\n",
       "                       -1.1519e-04, -2.4801e-04,  3.9750e-04, -4.0375e-04,  4.8559e-04,\n",
       "                        1.6143e-04, -4.0638e-04, -3.3682e-04,  4.5803e-04,  3.8779e-04,\n",
       "                       -3.0673e-04, -2.7750e-04, -4.2516e-04, -8.9884e-05, -3.3413e-05,\n",
       "                        4.1375e-04,  1.5640e-04, -3.2728e-04,  2.6550e-04,  6.4583e-04,\n",
       "                       -4.0793e-04, -4.6398e-04, -4.0610e-04,  5.8301e-04,  3.3042e-04,\n",
       "                        5.1148e-04,  3.6339e-04,  2.1625e-04,  2.4988e-04, -8.9571e-05,\n",
       "                        4.2623e-04, -2.0559e-04,  2.9538e-04,  2.1762e-04, -1.4870e-04])),\n",
       "              ('transformer_encoder.layers.1.inter_feature_attn.out_proj.weight',\n",
       "               tensor([[ 0.0735, -0.0695,  0.0130,  ...,  0.0984,  0.0150, -0.0568],\n",
       "                       [ 0.0273, -0.0901,  0.0102,  ...,  0.0859, -0.0627,  0.0383],\n",
       "                       [ 0.0488,  0.0714,  0.0972,  ..., -0.0041,  0.0882, -0.0622],\n",
       "                       ...,\n",
       "                       [-0.0378, -0.0222, -0.0973,  ...,  0.0504, -0.0180, -0.0571],\n",
       "                       [-0.0607,  0.0151,  0.0548,  ...,  0.0282, -0.0070, -0.0665],\n",
       "                       [-0.0881,  0.0082,  0.0160,  ...,  0.0986,  0.0365,  0.0698]])),\n",
       "              ('transformer_encoder.layers.1.inter_feature_attn.out_proj.bias',\n",
       "               tensor([ 5.2120e-04, -1.4905e-05,  5.5091e-04,  5.4250e-04,  2.8800e-04,\n",
       "                       -6.8651e-05, -3.2938e-04,  4.6620e-05,  3.6597e-04,  3.4604e-04,\n",
       "                       -4.1602e-04, -4.3091e-04, -5.3095e-04,  4.6512e-04, -3.8755e-04,\n",
       "                       -1.7565e-04,  1.8468e-04,  3.7326e-04,  5.6047e-05, -3.7965e-04,\n",
       "                        1.0812e-04,  2.2692e-04,  1.5224e-04,  1.5289e-04, -4.6292e-04,\n",
       "                        3.4585e-04, -4.2491e-04,  2.9279e-04, -1.6600e-04,  1.6928e-04,\n",
       "                       -4.1358e-04,  4.0683e-04,  3.8474e-04, -4.2973e-04,  2.9292e-06,\n",
       "                        1.6997e-04,  6.2255e-04, -3.5470e-04, -4.1976e-04,  1.4841e-04,\n",
       "                       -3.6591e-04,  4.4479e-04, -1.9834e-04, -5.2936e-04, -3.6886e-04,\n",
       "                       -5.0431e-04,  6.2671e-04,  4.7794e-04, -4.8224e-04, -2.2703e-04,\n",
       "                       -3.2711e-04,  3.6042e-04,  3.7662e-04, -4.9264e-04,  4.2140e-04,\n",
       "                        4.1265e-04, -4.9833e-04,  3.2165e-04,  4.1587e-04,  2.7026e-04,\n",
       "                        3.2315e-04, -5.6688e-04,  1.8947e-04,  3.2244e-04, -6.3032e-04,\n",
       "                        3.5206e-04,  4.8533e-04,  2.9311e-05, -1.1599e-04, -5.1260e-04,\n",
       "                       -3.2109e-04,  1.3507e-05,  3.1199e-04, -1.8120e-04,  2.1193e-04,\n",
       "                       -4.6817e-04,  4.4216e-04,  6.0575e-04,  3.3065e-04, -4.1901e-04,\n",
       "                        3.1628e-04, -2.0900e-04,  7.4225e-05, -4.0751e-04,  6.2857e-04,\n",
       "                        2.5507e-04, -2.8109e-04,  3.5823e-04,  5.8778e-04,  4.7688e-04,\n",
       "                       -3.0765e-04,  5.8580e-04, -4.2695e-04, -1.3826e-05, -6.8452e-05,\n",
       "                       -2.5893e-04, -4.5442e-04, -3.4902e-04,  7.2976e-05,  5.3724e-04])),\n",
       "              ('transformer_encoder.layers.1.pre_linear2.weight',\n",
       "               tensor([[-0.0751,  0.0180, -0.0341,  ...,  0.0419,  0.0554,  0.0466],\n",
       "                       [ 0.0158,  0.0492, -0.0050,  ..., -0.0208,  0.0390, -0.0878],\n",
       "                       [ 0.0205,  0.0507, -0.0430,  ..., -0.0213, -0.0247, -0.0254],\n",
       "                       ...,\n",
       "                       [ 0.0913,  0.0990, -0.0160,  ...,  0.0178,  0.0845,  0.0876],\n",
       "                       [-0.0698,  0.0125, -0.0471,  ..., -0.0062, -0.0178, -0.0921],\n",
       "                       [-0.0651,  0.0325,  0.0787,  ..., -0.0919, -0.0058,  0.0687]])),\n",
       "              ('transformer_encoder.layers.1.pre_linear2.bias',\n",
       "               tensor([ 0.0917,  0.0331,  0.0822,  ...,  0.0343,  0.0332, -0.0612])),\n",
       "              ('transformer_encoder.layers.1.pre_linear3.weight',\n",
       "               tensor([[-0.0259,  0.0071,  0.0124,  ...,  0.0146,  0.0035, -0.0058]])),\n",
       "              ('transformer_encoder.layers.1.pre_linear3.bias',\n",
       "               tensor([0.0177])),\n",
       "              ('transformer_encoder.layers.1.pre_norm_.weight',\n",
       "               tensor([0.9997, 0.9997, 0.9998, 0.9992, 0.9993, 0.9991, 0.9991, 1.0000, 1.0000,\n",
       "                       0.9993, 0.9995, 0.9991, 0.9994, 0.9994, 0.9991, 1.0000, 1.0000, 0.9996,\n",
       "                       0.9991, 0.9993, 0.9999, 0.9992, 0.9996, 0.9998, 1.0004, 0.9995, 0.9991,\n",
       "                       0.9995, 0.9994, 0.9991, 0.9998, 1.0007, 1.0005, 0.9996, 0.9998, 0.9995,\n",
       "                       1.0004, 0.9992, 0.9992, 1.0005, 0.9997, 0.9991, 0.9991, 1.0006, 0.9996,\n",
       "                       0.9996, 1.0006, 0.9994, 0.9996, 0.9993, 0.9994, 0.9992, 0.9994, 0.9996,\n",
       "                       1.0000, 1.0002, 0.9996, 1.0001, 0.9996, 0.9993, 0.9991, 1.0002, 1.0006,\n",
       "                       1.0000, 0.9993, 0.9998, 0.9999, 1.0001, 0.9991, 0.9995, 1.0000, 1.0009,\n",
       "                       1.0001, 0.9993, 0.9995, 0.9997, 1.0000, 1.0003, 0.9997, 1.0001, 0.9993,\n",
       "                       0.9996, 0.9993, 0.9993, 0.9993, 0.9999, 0.9999, 0.9995, 0.9997, 0.9993,\n",
       "                       0.9998, 0.9991, 0.9989, 0.9993, 0.9998, 1.0004, 0.9996, 0.9994, 0.9996,\n",
       "                       0.9992])),\n",
       "              ('transformer_encoder.layers.1.pre_norm_.bias',\n",
       "               tensor([-4.8111e-04,  5.2689e-04, -4.0267e-04,  4.1164e-04, -1.2906e-04,\n",
       "                       -1.9757e-04,  4.6745e-04,  6.8267e-04,  5.5714e-04, -4.2778e-04,\n",
       "                       -4.5375e-04, -1.4353e-04,  8.5510e-05, -4.5234e-04,  2.4788e-04,\n",
       "                       -5.5569e-04, -4.0197e-04,  3.2236e-04,  2.8189e-04, -5.4072e-04,\n",
       "                        4.5710e-04, -2.7767e-04, -4.5505e-04,  5.1770e-04, -5.3455e-04,\n",
       "                       -5.9721e-04, -2.9842e-04, -5.6602e-04, -5.7328e-04,  3.3985e-04,\n",
       "                       -5.0097e-04,  7.3393e-04, -5.1271e-04,  5.5957e-04, -4.1042e-04,\n",
       "                        6.5885e-04,  5.1533e-04, -4.2520e-04,  5.3076e-04, -4.8746e-04,\n",
       "                        4.9837e-04, -3.5761e-04, -4.1524e-04, -8.6682e-04,  2.8706e-04,\n",
       "                       -4.7119e-04,  6.3620e-04, -3.6566e-04, -4.9917e-04,  4.0013e-04,\n",
       "                       -4.4567e-04,  1.0536e-04, -1.0592e-04,  6.1237e-04, -5.2537e-04,\n",
       "                        7.1965e-04,  5.0263e-04,  5.7422e-04,  2.7455e-04, -1.9824e-04,\n",
       "                       -4.2914e-04, -5.6753e-04,  6.7942e-04, -4.9389e-04,  3.9159e-04,\n",
       "                        5.6261e-04,  1.5989e-04, -4.6699e-04, -4.2676e-04, -5.1426e-04,\n",
       "                        4.9035e-04,  5.9187e-04,  6.2793e-04,  4.3782e-06,  5.5342e-04,\n",
       "                        4.7743e-04, -4.3262e-04, -7.6377e-04, -4.4657e-04,  5.4453e-04,\n",
       "                        4.2337e-04, -4.2408e-04, -5.2232e-04, -5.2237e-04,  4.0288e-04,\n",
       "                       -5.9240e-04, -3.3515e-04, -4.9176e-04, -5.3576e-04, -4.6191e-04,\n",
       "                        6.2941e-04, -1.2252e-04, -2.3345e-04,  2.5775e-04,  4.5719e-04,\n",
       "                        5.5680e-04,  4.5766e-04,  4.8626e-04, -6.6539e-04, -5.0475e-04])),\n",
       "              ('transformer_encoder.layers.1.pre_linear4.weight',\n",
       "               tensor([[ 0.0615,  0.0936, -0.0017,  ...,  0.0368,  0.0329,  0.0005],\n",
       "                       [-0.0163,  0.0758, -0.0733,  ...,  0.0344,  0.0740, -0.0874],\n",
       "                       [-0.0126,  0.0787,  0.0189,  ...,  0.0695, -0.0261,  0.0031],\n",
       "                       ...,\n",
       "                       [-0.0389,  0.0124, -0.0607,  ..., -0.0823,  0.0195, -0.0054],\n",
       "                       [ 0.0658, -0.0541, -0.0820,  ..., -0.0863,  0.0432,  0.0346],\n",
       "                       [ 0.0306, -0.0282, -0.0951,  ..., -0.0586,  0.0425, -0.0221]])),\n",
       "              ('transformer_encoder.layers.1.pre_linear4.bias',\n",
       "               tensor([ 0.0388, -0.0760,  0.0630,  ...,  0.0820, -0.0772, -0.0714])),\n",
       "              ('transformer_encoder.layers.1.pre_linear5.weight',\n",
       "               tensor([[ 0.0049,  0.0034, -0.0142,  ..., -0.0024, -0.0142, -0.0243],\n",
       "                       [-0.0194, -0.0186, -0.0234,  ...,  0.0074,  0.0229, -0.0312],\n",
       "                       [-0.0133, -0.0181,  0.0235,  ...,  0.0102, -0.0255,  0.0327],\n",
       "                       ...,\n",
       "                       [-0.0280, -0.0015,  0.0006,  ...,  0.0160,  0.0151,  0.0053],\n",
       "                       [-0.0113, -0.0096, -0.0278,  ...,  0.0178, -0.0064,  0.0308],\n",
       "                       [-0.0207, -0.0183, -0.0005,  ..., -0.0091,  0.0009, -0.0131]])),\n",
       "              ('transformer_encoder.layers.1.pre_linear5.bias',\n",
       "               tensor([-2.5943e-02, -1.5105e-03,  1.6476e-02,  3.0738e-02, -1.0564e-02,\n",
       "                        1.7830e-03,  1.9518e-02, -1.0811e-02, -1.6661e-02,  2.5689e-02,\n",
       "                       -2.6575e-02, -1.1928e-02,  1.9970e-02, -3.1894e-04,  2.3493e-03,\n",
       "                       -2.3957e-03, -1.2776e-03,  1.9993e-02, -2.3788e-03, -2.4925e-02,\n",
       "                        1.5917e-02,  2.4676e-03,  2.0888e-03,  1.0954e-02,  1.5098e-02,\n",
       "                        1.0923e-02,  9.7139e-03,  1.4396e-02, -1.2535e-02,  1.4571e-02,\n",
       "                        3.7949e-03,  2.4067e-02, -6.1202e-03,  6.9213e-03, -2.5505e-03,\n",
       "                        1.2191e-02,  2.0476e-02, -2.6797e-02, -8.2730e-03, -1.3031e-02,\n",
       "                       -3.0739e-02, -6.9801e-03, -2.4154e-02,  2.1242e-02, -1.0347e-02,\n",
       "                        4.9268e-03,  2.7400e-02, -1.6451e-02, -2.1529e-02, -1.3277e-02,\n",
       "                        8.7997e-03,  2.4012e-02,  6.2543e-03,  2.3813e-04,  1.5647e-02,\n",
       "                       -1.7526e-03,  6.5030e-03, -2.1475e-02, -5.5984e-03,  2.4879e-02,\n",
       "                        2.1616e-02,  1.1669e-02,  2.9409e-02, -1.8231e-03, -3.0932e-02,\n",
       "                        1.9392e-02, -1.3810e-02, -1.6261e-02, -1.5526e-02, -2.3519e-02,\n",
       "                        7.3524e-03,  2.1581e-03, -6.7887e-03,  1.5452e-02, -2.1231e-02,\n",
       "                       -1.2259e-02,  2.0021e-03, -2.5713e-02, -4.9720e-03, -2.5152e-02,\n",
       "                       -1.7922e-02, -2.2955e-03,  1.1278e-02,  1.5535e-02,  1.9356e-02,\n",
       "                       -2.2266e-02, -4.1524e-03, -2.5117e-02,  2.9499e-02,  2.1198e-02,\n",
       "                       -4.5850e-03, -1.6701e-02,  6.5765e-03, -1.1528e-02,  2.9119e-02,\n",
       "                        1.9381e-02, -2.2550e-02,  2.4882e-04,  7.8358e-03, -1.7200e-02,\n",
       "                        4.6480e-03,  6.0406e-03, -7.6914e-03,  5.0951e-03, -2.6655e-02,\n",
       "                       -1.3967e-02, -1.5325e-02, -2.1820e-02,  2.6797e-02,  8.0151e-03,\n",
       "                       -3.2611e-03, -2.3498e-02,  1.9733e-02,  3.1902e-02, -2.0011e-02,\n",
       "                        1.5222e-02, -1.4643e-02, -2.4784e-02,  3.0056e-02, -2.8187e-02,\n",
       "                        3.1869e-03, -1.5113e-02,  8.7461e-03,  3.1054e-02, -1.3630e-02,\n",
       "                        1.2175e-02, -1.7226e-02,  1.7557e-02,  3.2012e-02,  2.3114e-02,\n",
       "                        2.2932e-02,  1.1082e-02, -2.3635e-03, -2.3488e-02,  8.5263e-03,\n",
       "                       -2.0223e-02, -2.9674e-02,  1.8586e-02,  2.8912e-03, -2.3166e-02,\n",
       "                       -1.3452e-02,  2.9566e-02,  1.8545e-02, -1.9569e-02,  1.8776e-03,\n",
       "                        2.6123e-02,  5.7677e-03, -2.5573e-02, -2.6260e-02, -2.4906e-02,\n",
       "                        2.8491e-02,  2.2862e-02, -1.4856e-02, -1.0499e-02,  7.5432e-03,\n",
       "                        9.5522e-03,  2.7383e-02,  2.4604e-02, -2.6715e-02, -1.7379e-03,\n",
       "                       -2.5355e-02, -2.6082e-02, -2.6447e-02, -3.0056e-02,  1.3993e-02,\n",
       "                       -1.1327e-02, -8.9185e-04,  1.9360e-02, -2.2428e-02,  1.3131e-02,\n",
       "                        1.9838e-02, -1.9503e-02, -5.4851e-03,  2.5919e-02, -2.4710e-02,\n",
       "                        1.6119e-02, -2.8095e-02, -2.3040e-03, -5.6708e-03,  2.6618e-02,\n",
       "                        2.6755e-02, -2.9658e-02,  1.1212e-02, -3.5296e-03, -2.4309e-02,\n",
       "                        1.8837e-02, -6.5396e-03, -8.9684e-03, -1.9948e-02, -1.7916e-02,\n",
       "                       -1.3481e-02,  1.2967e-02,  3.2367e-02, -1.2552e-02, -1.6129e-02,\n",
       "                        8.7383e-03,  4.1633e-03, -4.2674e-03,  3.2332e-02,  2.4425e-02,\n",
       "                       -1.1187e-02, -1.5698e-02,  1.0158e-02, -7.2947e-03, -2.3438e-04,\n",
       "                       -5.4625e-03,  6.1959e-04,  2.6690e-02,  7.8872e-03, -9.4857e-03,\n",
       "                        1.5489e-02,  1.5719e-02,  3.1824e-02, -2.1356e-03,  2.7302e-02,\n",
       "                        2.7540e-02, -3.4839e-03,  2.3961e-02,  5.1964e-03,  2.1540e-02,\n",
       "                       -2.5500e-02, -3.1193e-04,  2.9838e-03,  5.7656e-03,  9.5065e-03,\n",
       "                       -3.4986e-03,  2.4412e-02,  8.1772e-03, -5.1000e-03,  1.3793e-02,\n",
       "                        1.6101e-02,  2.8646e-02,  1.1671e-03,  1.0905e-02,  1.0300e-02,\n",
       "                        2.4655e-02,  1.8552e-02, -4.5173e-03, -2.8495e-02, -1.9636e-02,\n",
       "                        2.3357e-02,  1.4309e-02,  1.2687e-02, -2.1678e-02, -2.9748e-02,\n",
       "                        2.5287e-02,  3.0085e-02, -4.0959e-03, -1.3735e-02,  1.7585e-02,\n",
       "                       -2.0084e-02,  1.6084e-02,  2.3909e-02,  3.2208e-03, -1.9503e-02,\n",
       "                       -2.3530e-02, -1.3862e-02, -3.0685e-02,  3.1021e-03, -1.4086e-02,\n",
       "                       -5.0311e-03,  2.8969e-02,  2.9320e-02, -4.4117e-03, -1.0137e-02,\n",
       "                       -1.5329e-02,  2.2576e-03,  1.2546e-02, -2.0206e-02, -1.1400e-02,\n",
       "                       -3.0716e-02, -8.7518e-03, -1.9827e-02,  1.5940e-03,  1.9384e-02,\n",
       "                       -9.0981e-03, -2.2403e-03, -3.2198e-02,  9.5587e-03, -7.2525e-03,\n",
       "                        2.2520e-02,  2.1556e-02, -6.3346e-03, -2.3258e-02,  2.4098e-02,\n",
       "                       -6.4544e-04,  4.1385e-03,  1.8432e-02,  1.0949e-02,  2.6067e-02,\n",
       "                       -2.0908e-02, -2.1805e-03, -1.3312e-02, -1.0908e-02,  9.0157e-03,\n",
       "                        1.3724e-02, -5.2901e-03, -1.4401e-02, -1.2807e-02, -1.2174e-02,\n",
       "                       -2.1670e-02,  2.3694e-02,  2.1671e-03,  3.2280e-02, -9.6119e-03,\n",
       "                       -1.4023e-02,  9.0666e-03,  1.8340e-02, -3.1004e-02, -7.7816e-03,\n",
       "                       -2.1490e-04,  1.1320e-02,  3.0050e-02, -2.7670e-02,  1.8629e-02,\n",
       "                       -4.7738e-03, -8.4804e-03,  3.0987e-02, -1.8429e-02,  2.2122e-02,\n",
       "                       -2.2216e-02, -1.8844e-02, -3.1829e-02, -1.6148e-02, -2.0658e-02,\n",
       "                        2.5460e-02,  2.6142e-02, -1.1784e-02,  3.0046e-02,  1.6218e-02,\n",
       "                        2.7983e-02,  4.4141e-03,  9.7375e-03, -1.4796e-02,  2.1672e-02,\n",
       "                       -1.7345e-02, -2.1721e-02, -3.1897e-02,  2.4136e-02, -2.7681e-02,\n",
       "                        5.2513e-03, -1.5656e-02, -2.5254e-02,  1.4516e-02,  1.1407e-02,\n",
       "                       -1.4456e-02,  1.6198e-02,  4.9573e-03,  4.2967e-04, -2.8454e-02,\n",
       "                        2.1284e-02, -2.3879e-02,  2.3348e-02, -1.9305e-02, -1.4161e-02,\n",
       "                        4.2972e-03, -2.1846e-02, -1.7928e-02,  1.6371e-03,  2.2784e-02,\n",
       "                        1.2188e-02,  9.5495e-03, -2.3092e-02,  2.5708e-02,  2.8922e-02,\n",
       "                       -1.0313e-02,  1.6978e-02, -4.0191e-03,  1.0102e-02,  1.2072e-02,\n",
       "                       -6.5570e-03, -1.5005e-02,  1.9398e-02, -9.5473e-03, -1.1598e-02,\n",
       "                        2.6455e-03,  2.5775e-02,  1.6116e-03, -2.6640e-02,  8.9148e-03,\n",
       "                        2.4565e-02, -3.2315e-02,  1.1185e-02,  1.6828e-02, -2.4154e-02,\n",
       "                        2.7019e-02, -1.1461e-02, -3.0418e-03, -1.4177e-02,  1.7464e-03,\n",
       "                        1.5584e-02,  2.4240e-02, -4.0416e-03, -1.1782e-02,  2.1621e-02,\n",
       "                       -3.0452e-02, -2.1793e-02, -1.0534e-02,  1.0987e-02,  2.6044e-03,\n",
       "                       -2.7184e-02, -3.9623e-03, -8.0642e-03, -3.2534e-02, -2.7734e-02,\n",
       "                        1.6668e-02, -1.9376e-02,  1.7893e-02,  1.8818e-02, -1.8396e-03,\n",
       "                        5.7671e-03,  2.1602e-02,  1.5162e-03,  2.0761e-02, -1.5841e-02,\n",
       "                       -8.8669e-03, -2.8207e-02, -1.9396e-03,  5.5190e-03,  1.7932e-02,\n",
       "                        2.4405e-02, -2.5235e-03,  3.4351e-03, -2.0939e-02,  3.0472e-02,\n",
       "                       -5.6332e-03, -1.2366e-02,  5.2818e-03,  3.2154e-03,  1.6501e-02,\n",
       "                       -2.0228e-02,  7.0554e-03,  2.3433e-02,  4.1700e-03, -1.8990e-04,\n",
       "                       -3.9303e-04,  1.6319e-02,  1.4034e-02,  2.6750e-02, -3.9236e-03,\n",
       "                        2.8409e-02, -7.3153e-03, -3.0472e-02,  1.9708e-02, -1.8510e-02,\n",
       "                       -3.1754e-02, -2.7772e-02, -2.6380e-02,  4.8345e-03, -8.1037e-03,\n",
       "                       -3.9312e-03, -1.7738e-02,  2.4488e-02, -1.7135e-02, -1.5819e-02,\n",
       "                        2.0746e-03,  1.3970e-02,  2.1737e-02, -3.0846e-02,  1.1273e-02,\n",
       "                       -1.0501e-02,  1.5894e-02,  2.4282e-02, -1.7500e-02, -2.7256e-02,\n",
       "                        1.8032e-02, -1.7914e-05,  6.1124e-03, -3.0685e-02, -4.0784e-03,\n",
       "                       -1.8486e-02,  2.5392e-02,  1.7985e-02, -2.4799e-02,  1.3703e-02,\n",
       "                       -1.9845e-02,  6.9244e-03, -1.7478e-02, -1.1810e-03, -5.0943e-03,\n",
       "                        1.2746e-02, -1.9015e-02, -2.2721e-02, -1.8936e-02, -2.1135e-02,\n",
       "                       -4.3895e-03, -1.4602e-02,  2.6008e-02, -3.2316e-02,  2.8059e-02,\n",
       "                       -2.5164e-02,  2.7660e-02,  2.7461e-02, -1.5239e-02, -9.8920e-03,\n",
       "                       -2.8642e-02,  9.6816e-03,  1.3480e-02, -5.0480e-04,  2.6715e-02,\n",
       "                        1.1220e-02, -2.2932e-02,  1.8451e-02, -2.4830e-02,  1.8637e-02,\n",
       "                        1.9921e-02, -1.9541e-02,  2.9157e-02,  1.7665e-02,  1.4803e-02,\n",
       "                       -2.4317e-02, -1.1618e-02])),\n",
       "              ('transformer_encoder.layers.1.linear1.weight',\n",
       "               tensor([[-0.0357, -0.0217,  0.0092,  ...,  0.0006, -0.0139,  0.0055],\n",
       "                       [ 0.0132, -0.0241, -0.0245,  ...,  0.0310, -0.0030,  0.0374],\n",
       "                       [ 0.0272, -0.0398, -0.0269,  ..., -0.0319,  0.0192, -0.0237],\n",
       "                       ...,\n",
       "                       [ 0.0327, -0.0072, -0.0187,  ...,  0.0235,  0.0325,  0.0451],\n",
       "                       [ 0.0445, -0.0427,  0.0379,  ..., -0.0295, -0.0089,  0.0166],\n",
       "                       [ 0.0375, -0.0320,  0.0332,  ...,  0.0274,  0.0099,  0.0415]])),\n",
       "              ('transformer_encoder.layers.1.linear1.bias',\n",
       "               tensor([-0.0407,  0.0247,  0.0029,  ...,  0.0370,  0.0305,  0.0444])),\n",
       "              ('transformer_encoder.layers.1.linear2.weight',\n",
       "               tensor([[-8.4567e-04,  7.6690e-04, -1.0411e-03,  ..., -1.1714e-03,\n",
       "                        -8.7182e-04, -1.2245e-04],\n",
       "                       [ 1.0372e-03, -8.9838e-04,  1.1320e-03,  ...,  1.3285e-03,\n",
       "                         1.0313e-03,  1.4823e-04],\n",
       "                       [-5.4473e-04,  6.2664e-04, -3.4008e-05,  ..., -7.6873e-06,\n",
       "                        -7.4051e-04, -1.9787e-04],\n",
       "                       ...,\n",
       "                       [ 9.8705e-04, -8.0032e-04,  9.0703e-04,  ...,  1.0013e-03,\n",
       "                         8.9011e-04,  1.8701e-04],\n",
       "                       [-1.2293e-03,  1.0702e-03, -5.5013e-04,  ..., -1.0007e-03,\n",
       "                        -1.2092e-03, -9.8487e-05],\n",
       "                       [-5.4550e-04,  7.6707e-04, -1.3944e-04,  ..., -5.4242e-04,\n",
       "                        -9.0514e-04, -1.2412e-04]])),\n",
       "              ('transformer_encoder.layers.1.linear2.bias',\n",
       "               tensor([-4.7451e-04,  5.3064e-04, -4.0762e-04,  4.1401e-04, -2.2865e-04,\n",
       "                       -3.2624e-05,  4.2951e-04,  6.2597e-04,  5.7663e-04, -4.3136e-04,\n",
       "                       -4.6243e-04, -1.1216e-04,  6.2380e-06, -4.5768e-04,  2.5783e-04,\n",
       "                       -5.7011e-04, -3.6618e-04,  2.1222e-04,  3.1627e-04, -5.5213e-04,\n",
       "                        4.5266e-04, -2.0910e-04, -4.6490e-04,  5.1051e-04, -5.2301e-04,\n",
       "                       -5.3660e-04, -2.9082e-04, -5.4892e-04, -5.6251e-04,  3.4527e-04,\n",
       "                       -5.3431e-04,  7.0255e-04, -5.1083e-04,  5.4298e-04, -4.3762e-04,\n",
       "                        6.4262e-04,  4.9752e-04, -4.3554e-04,  4.9464e-04, -4.8901e-04,\n",
       "                        5.0516e-04, -3.7426e-04, -4.4072e-04, -8.7190e-04,  2.6677e-04,\n",
       "                       -4.6459e-04,  6.4747e-04, -3.7118e-04, -5.1297e-04,  3.9063e-04,\n",
       "                       -4.4198e-04,  8.6853e-05, -3.5959e-05,  6.0843e-04, -5.4053e-04,\n",
       "                        7.1387e-04,  4.4146e-04,  5.7443e-04,  3.1678e-04, -1.8944e-04,\n",
       "                       -3.9382e-04, -5.5847e-04,  6.8187e-04, -4.8253e-04,  3.8795e-04,\n",
       "                        5.6090e-04,  1.8302e-04, -4.7932e-04, -4.5453e-04, -5.3656e-04,\n",
       "                        4.8055e-04,  5.9253e-04,  6.1007e-04,  4.6722e-05,  5.7754e-04,\n",
       "                        4.7485e-04, -4.0319e-04, -7.4967e-04, -4.2691e-04,  5.2339e-04,\n",
       "                        4.4727e-04, -4.0784e-04, -5.1245e-04, -5.2223e-04,  3.9764e-04,\n",
       "                       -5.6881e-04, -2.8853e-04, -4.9157e-04, -5.3580e-04, -4.2997e-04,\n",
       "                        5.8701e-04, -1.3312e-04, -1.7532e-05,  2.5028e-04,  4.2774e-04,\n",
       "                        5.4889e-04,  4.6010e-04,  4.7870e-04, -6.8429e-04, -5.1156e-04])),\n",
       "              ('transformer_encoder.layers.1.norm1.weight',\n",
       "               tensor([1.0020, 1.0020, 1.0019, 1.0018, 1.0019, 1.0020, 1.0021, 1.0020, 1.0021,\n",
       "                       1.0021, 1.0020, 1.0017, 1.0021, 1.0020, 1.0018, 1.0022, 1.0021, 1.0021,\n",
       "                       1.0019, 1.0020, 1.0021, 1.0020, 1.0019, 1.0018, 1.0018, 1.0021, 1.0020,\n",
       "                       1.0014, 1.0020, 1.0019, 1.0020, 1.0018, 1.0020, 1.0020, 1.0015, 1.0020,\n",
       "                       1.0020, 1.0019, 1.0020, 1.0020, 1.0018, 1.0017, 1.0020, 1.0020, 1.0019,\n",
       "                       1.0021, 1.0021, 1.0020, 1.0019, 1.0019, 1.0020, 1.0019, 1.0021, 1.0017,\n",
       "                       1.0021, 1.0021, 1.0011, 1.0020, 1.0018, 1.0020, 1.0020, 1.0020, 1.0021,\n",
       "                       1.0018, 1.0020, 1.0018, 1.0018, 1.0020, 1.0020, 1.0021, 1.0021, 1.0021,\n",
       "                       1.0019, 1.0011, 1.0019, 1.0021, 1.0021, 1.0020, 1.0020, 1.0017, 1.0020,\n",
       "                       1.0018, 1.0019, 1.0019, 1.0021, 1.0019, 1.0020, 1.0020, 1.0021, 1.0020,\n",
       "                       1.0020, 1.0020, 1.0019, 1.0021, 1.0017, 1.0019, 1.0021, 1.0019, 1.0018,\n",
       "                       1.0020, 1.0019, 1.0021, 1.0021, 1.0022, 1.0014, 1.0019, 1.0014, 1.0021,\n",
       "                       1.0015, 1.0013, 1.0019, 1.0020, 1.0019, 1.0020, 1.0021, 1.0020, 1.0015,\n",
       "                       1.0019, 1.0019, 1.0020, 1.0019, 1.0019, 1.0020, 1.0019, 1.0021, 1.0019,\n",
       "                       1.0020, 1.0012, 1.0021, 1.0020, 1.0017, 1.0020, 1.0019, 1.0020, 1.0020,\n",
       "                       1.0020, 1.0018, 1.0021, 1.0022, 1.0021, 1.0017, 1.0018, 1.0020, 1.0018,\n",
       "                       1.0020, 1.0020, 1.0020, 1.0020, 1.0018, 1.0021, 1.0018, 1.0020, 1.0019,\n",
       "                       1.0019, 1.0017, 1.0020, 1.0019, 1.0021, 1.0018, 1.0019, 1.0020, 1.0020,\n",
       "                       1.0021, 1.0020, 1.0021, 1.0020, 1.0020, 1.0020, 1.0020, 1.0020, 1.0020,\n",
       "                       1.0022, 1.0017, 1.0021, 1.0021, 1.0020, 1.0019, 1.0019, 1.0021, 1.0020,\n",
       "                       1.0021, 1.0021, 1.0021, 1.0020, 1.0020, 1.0016, 1.0019, 1.0019, 1.0021,\n",
       "                       1.0018, 1.0021, 1.0020, 1.0020, 1.0021, 1.0021, 1.0020, 1.0011, 1.0019,\n",
       "                       1.0017, 1.0016, 1.0019, 1.0018, 1.0021, 1.0018, 1.0020, 1.0020, 1.0017,\n",
       "                       1.0019, 1.0019, 1.0019, 1.0020, 1.0017, 1.0020, 1.0019, 1.0018, 1.0021,\n",
       "                       1.0012, 1.0021, 1.0020, 1.0019, 1.0021, 1.0019, 1.0020, 1.0022, 1.0019,\n",
       "                       1.0021, 1.0021, 1.0020, 1.0020, 1.0020, 1.0019, 1.0020, 1.0019, 1.0020,\n",
       "                       1.0021, 1.0020, 1.0019, 1.0020, 1.0020, 1.0020, 1.0018, 1.0021, 1.0017,\n",
       "                       1.0019, 1.0020, 1.0020, 1.0018, 1.0020, 1.0021, 1.0017, 1.0021, 1.0021,\n",
       "                       1.0015, 1.0021, 1.0017, 1.0019, 1.0020, 1.0020, 1.0019, 1.0020, 1.0020,\n",
       "                       1.0020, 1.0013, 1.0019, 1.0019, 1.0022, 1.0014, 1.0020, 1.0020, 1.0020,\n",
       "                       1.0021, 1.0018, 1.0018, 1.0018, 1.0022, 1.0018, 1.0020, 1.0020, 1.0020,\n",
       "                       1.0020, 1.0019, 1.0019, 1.0019, 1.0019, 1.0021, 1.0019, 1.0021, 1.0021,\n",
       "                       1.0020, 1.0020, 1.0018, 1.0020, 1.0020, 1.0022, 1.0021, 1.0020, 1.0019,\n",
       "                       1.0012, 1.0020, 1.0019, 1.0021, 1.0015, 1.0019, 1.0021, 1.0021, 1.0019,\n",
       "                       1.0019, 1.0020, 1.0019, 1.0018, 1.0019, 1.0019, 1.0014, 1.0020, 1.0022,\n",
       "                       1.0021, 1.0019, 1.0019, 1.0016, 1.0020, 1.0020, 1.0020, 1.0021, 1.0021,\n",
       "                       1.0021, 1.0021, 1.0020, 1.0013, 1.0021, 1.0020, 1.0018, 1.0019, 1.0020,\n",
       "                       1.0020, 1.0019, 1.0020, 1.0019, 1.0020, 1.0021, 1.0020, 1.0021, 1.0021,\n",
       "                       1.0019, 1.0021, 1.0019, 1.0021, 1.0020, 1.0019, 1.0019, 1.0019, 1.0019,\n",
       "                       1.0020, 1.0017, 1.0020, 1.0022, 1.0019, 1.0018, 1.0019, 1.0020, 1.0020,\n",
       "                       1.0021, 1.0021, 1.0015, 1.0020, 1.0019, 1.0018, 1.0020, 1.0019, 1.0016,\n",
       "                       1.0019, 1.0020, 1.0020, 1.0019, 1.0017, 1.0020, 1.0020, 1.0019, 1.0017,\n",
       "                       1.0019, 1.0018, 1.0019, 1.0020, 1.0017, 1.0020, 1.0021, 1.0020, 1.0018,\n",
       "                       1.0015, 1.0020, 1.0021, 1.0013, 1.0018, 1.0020, 1.0021, 1.0019, 1.0019,\n",
       "                       1.0019, 1.0019, 1.0020, 1.0020, 1.0011, 1.0020, 1.0022, 1.0019, 1.0020,\n",
       "                       1.0020, 1.0020, 1.0019, 1.0020, 1.0021, 1.0015, 1.0020, 1.0020, 1.0020,\n",
       "                       1.0019, 1.0018, 1.0018, 1.0020, 1.0015, 1.0017, 1.0018, 1.0020, 1.0020,\n",
       "                       1.0019, 1.0022, 1.0021, 1.0021, 1.0020, 1.0019, 1.0019, 1.0019, 1.0020,\n",
       "                       1.0020, 1.0021, 1.0019, 1.0020, 1.0018, 1.0020, 1.0020, 1.0018, 1.0018,\n",
       "                       1.0021, 1.0020, 1.0021, 1.0020, 1.0019, 1.0019, 1.0021, 1.0021, 1.0019,\n",
       "                       1.0019, 1.0021, 1.0019, 1.0022, 1.0021, 1.0020, 1.0019, 1.0018, 1.0019,\n",
       "                       1.0011, 1.0019, 1.0020, 1.0020, 1.0020, 1.0018, 1.0020, 1.0019, 1.0020,\n",
       "                       1.0021, 1.0021, 1.0015, 1.0021, 1.0021, 1.0020, 1.0021, 1.0017, 1.0019,\n",
       "                       1.0018, 1.0019, 1.0020, 1.0020, 1.0020, 1.0018, 1.0019, 1.0019, 1.0019,\n",
       "                       1.0020, 1.0019, 1.0020, 1.0021, 1.0018, 1.0018, 1.0020, 1.0021, 1.0020,\n",
       "                       1.0020, 1.0018, 1.0021, 1.0020, 1.0018, 1.0020, 1.0019, 1.0020, 1.0021,\n",
       "                       1.0019, 1.0020, 1.0021, 1.0018, 1.0018, 1.0021, 1.0020, 1.0020])),\n",
       "              ('transformer_encoder.layers.1.norm1.bias',\n",
       "               tensor([ 0.0020, -0.0020,  0.0019,  0.0018, -0.0019, -0.0019,  0.0020,  0.0020,\n",
       "                        0.0018,  0.0019,  0.0019, -0.0018, -0.0017,  0.0019,  0.0018,  0.0021,\n",
       "                        0.0019, -0.0020, -0.0019, -0.0019, -0.0021, -0.0020, -0.0019, -0.0008,\n",
       "                        0.0018, -0.0021,  0.0019, -0.0019, -0.0019,  0.0020,  0.0019,  0.0019,\n",
       "                       -0.0019,  0.0019,  0.0018,  0.0019, -0.0020, -0.0021, -0.0019, -0.0019,\n",
       "                       -0.0019,  0.0019, -0.0019,  0.0019, -0.0019, -0.0014,  0.0020, -0.0019,\n",
       "                       -0.0022,  0.0019,  0.0019,  0.0019, -0.0019, -0.0019,  0.0020, -0.0021,\n",
       "                       -0.0002, -0.0019,  0.0020, -0.0019, -0.0019, -0.0019,  0.0019,  0.0018,\n",
       "                       -0.0019,  0.0018,  0.0019, -0.0020,  0.0020, -0.0020, -0.0017,  0.0020,\n",
       "                        0.0018, -0.0009,  0.0018,  0.0019, -0.0020,  0.0020,  0.0020,  0.0018,\n",
       "                       -0.0019, -0.0018,  0.0019,  0.0019, -0.0020,  0.0020,  0.0020,  0.0019,\n",
       "                       -0.0020, -0.0019, -0.0019,  0.0019, -0.0019,  0.0021,  0.0019,  0.0019,\n",
       "                        0.0020, -0.0019, -0.0019, -0.0019,  0.0019, -0.0020,  0.0020, -0.0021,\n",
       "                       -0.0008, -0.0018, -0.0021,  0.0019,  0.0021,  0.0020, -0.0019,  0.0020,\n",
       "                       -0.0019,  0.0019, -0.0020,  0.0019,  0.0020, -0.0020,  0.0019, -0.0019,\n",
       "                        0.0019, -0.0020, -0.0019,  0.0018,  0.0015, -0.0019,  0.0019,  0.0002,\n",
       "                        0.0019, -0.0020, -0.0020,  0.0019,  0.0020,  0.0020,  0.0019, -0.0020,\n",
       "                       -0.0020, -0.0020, -0.0020,  0.0020, -0.0019,  0.0018,  0.0019, -0.0020,\n",
       "                       -0.0019, -0.0020, -0.0019,  0.0019,  0.0022,  0.0020, -0.0012,  0.0019,\n",
       "                       -0.0018, -0.0019, -0.0018, -0.0019,  0.0019,  0.0019, -0.0018,  0.0019,\n",
       "                       -0.0019,  0.0019, -0.0020, -0.0019,  0.0021,  0.0019,  0.0019, -0.0021,\n",
       "                       -0.0019, -0.0019, -0.0020,  0.0019, -0.0018, -0.0020, -0.0021, -0.0019,\n",
       "                       -0.0019,  0.0018, -0.0019,  0.0019, -0.0019, -0.0020, -0.0020, -0.0019,\n",
       "                       -0.0019,  0.0019, -0.0019,  0.0019, -0.0020, -0.0019,  0.0019, -0.0020,\n",
       "                        0.0020, -0.0020,  0.0021, -0.0021,  0.0007, -0.0019,  0.0018,  0.0020,\n",
       "                        0.0018, -0.0019,  0.0020, -0.0018,  0.0020,  0.0019, -0.0018,  0.0019,\n",
       "                       -0.0019,  0.0018,  0.0020,  0.0019,  0.0019, -0.0018,  0.0018,  0.0020,\n",
       "                        0.0011, -0.0020,  0.0020,  0.0020, -0.0020,  0.0019, -0.0019,  0.0020,\n",
       "                       -0.0019,  0.0019,  0.0020,  0.0019, -0.0019, -0.0020, -0.0018, -0.0019,\n",
       "                        0.0018, -0.0021, -0.0020, -0.0019, -0.0019,  0.0021, -0.0020, -0.0020,\n",
       "                        0.0019, -0.0020,  0.0020, -0.0019, -0.0020,  0.0019,  0.0018,  0.0019,\n",
       "                       -0.0019,  0.0018,  0.0020,  0.0019, -0.0004,  0.0019,  0.0019, -0.0019,\n",
       "                       -0.0019, -0.0019,  0.0020,  0.0019,  0.0019, -0.0019, -0.0015,  0.0019,\n",
       "                        0.0019, -0.0022, -0.0017,  0.0019, -0.0019,  0.0019, -0.0020,  0.0019,\n",
       "                       -0.0019,  0.0018, -0.0020,  0.0018, -0.0019, -0.0019, -0.0019, -0.0021,\n",
       "                        0.0019,  0.0019,  0.0018,  0.0017,  0.0019, -0.0019, -0.0020,  0.0020,\n",
       "                       -0.0020,  0.0020, -0.0018,  0.0020, -0.0017, -0.0019,  0.0019,  0.0019,\n",
       "                        0.0019, -0.0012, -0.0019,  0.0019,  0.0020,  0.0020,  0.0019,  0.0020,\n",
       "                        0.0020,  0.0018,  0.0019, -0.0019, -0.0018,  0.0019,  0.0019, -0.0019,\n",
       "                        0.0018,  0.0019,  0.0019,  0.0020, -0.0018,  0.0019,  0.0021, -0.0020,\n",
       "                        0.0019,  0.0019, -0.0021,  0.0019,  0.0019,  0.0019, -0.0019,  0.0011,\n",
       "                        0.0019, -0.0019,  0.0019, -0.0019, -0.0019,  0.0020, -0.0021,  0.0019,\n",
       "                       -0.0019, -0.0019, -0.0021, -0.0019, -0.0020, -0.0020, -0.0019,  0.0019,\n",
       "                        0.0018, -0.0020, -0.0019,  0.0019,  0.0018, -0.0019,  0.0019, -0.0019,\n",
       "                       -0.0018,  0.0019, -0.0020, -0.0019, -0.0021, -0.0019,  0.0019, -0.0020,\n",
       "                       -0.0017,  0.0020, -0.0019, -0.0019,  0.0019, -0.0018,  0.0019, -0.0015,\n",
       "                        0.0021, -0.0018, -0.0020, -0.0019, -0.0019, -0.0018, -0.0019,  0.0019,\n",
       "                        0.0019, -0.0018,  0.0019, -0.0019,  0.0019, -0.0020,  0.0020, -0.0019,\n",
       "                       -0.0020,  0.0020,  0.0018, -0.0021,  0.0019,  0.0020,  0.0018,  0.0019,\n",
       "                        0.0019,  0.0020, -0.0019, -0.0019, -0.0020, -0.0021, -0.0019,  0.0020,\n",
       "                       -0.0013,  0.0020,  0.0021, -0.0018, -0.0020, -0.0019,  0.0019, -0.0018,\n",
       "                       -0.0015,  0.0020, -0.0019, -0.0019,  0.0020,  0.0019, -0.0019,  0.0019,\n",
       "                       -0.0018,  0.0019, -0.0021, -0.0019, -0.0019,  0.0020,  0.0019, -0.0020,\n",
       "                        0.0021,  0.0020,  0.0019,  0.0020, -0.0019, -0.0019,  0.0019, -0.0019,\n",
       "                        0.0019,  0.0019, -0.0019,  0.0020,  0.0018,  0.0020, -0.0018, -0.0019,\n",
       "                       -0.0018,  0.0020, -0.0020,  0.0020,  0.0019, -0.0019, -0.0019,  0.0021,\n",
       "                        0.0020, -0.0019, -0.0019, -0.0020,  0.0019,  0.0021, -0.0020,  0.0020,\n",
       "                        0.0018, -0.0019, -0.0018,  0.0017, -0.0019,  0.0020,  0.0014, -0.0019,\n",
       "                       -0.0018,  0.0019,  0.0021,  0.0020, -0.0020, -0.0019,  0.0018, -0.0020,\n",
       "                        0.0020, -0.0019,  0.0021,  0.0021,  0.0019, -0.0019, -0.0019,  0.0019,\n",
       "                       -0.0019,  0.0019, -0.0022, -0.0019, -0.0019,  0.0021, -0.0019, -0.0019,\n",
       "                       -0.0019,  0.0020, -0.0019,  0.0019, -0.0019,  0.0021,  0.0019,  0.0019,\n",
       "                       -0.0021, -0.0020, -0.0021,  0.0018, -0.0020,  0.0019,  0.0019,  0.0020,\n",
       "                       -0.0019,  0.0020,  0.0020, -0.0010, -0.0019, -0.0021, -0.0021,  0.0020])),\n",
       "              ('transformer_encoder.layers.1.norm2.weight',\n",
       "               tensor([1.0014, 1.0010, 1.0011, 1.0003, 1.0003, 1.0000, 1.0005, 1.0014, 1.0015,\n",
       "                       1.0004, 1.0010, 1.0002, 1.0002, 1.0005, 1.0000, 1.0013, 1.0008, 1.0008,\n",
       "                       1.0005, 1.0010, 1.0011, 1.0000, 1.0011, 1.0014, 1.0016, 1.0013, 1.0000,\n",
       "                       1.0013, 1.0010, 1.0007, 1.0012, 1.0018, 1.0016, 1.0011, 1.0009, 1.0014,\n",
       "                       1.0014, 1.0009, 1.0013, 1.0012, 1.0009, 0.9999, 1.0004, 1.0016, 1.0006,\n",
       "                       1.0009, 1.0017, 1.0002, 1.0009, 1.0002, 1.0003, 0.9996, 1.0005, 1.0009,\n",
       "                       1.0010, 1.0014, 1.0009, 1.0016, 1.0007, 1.0000, 1.0002, 1.0013, 1.0016,\n",
       "                       1.0015, 1.0006, 1.0009, 1.0005, 1.0014, 1.0002, 1.0009, 1.0015, 1.0015,\n",
       "                       1.0012, 1.0004, 1.0011, 1.0009, 1.0009, 1.0015, 1.0008, 1.0014, 1.0008,\n",
       "                       1.0010, 1.0009, 1.0008, 1.0003, 1.0016, 1.0007, 1.0006, 1.0008, 1.0007,\n",
       "                       1.0015, 1.0000, 0.9997, 1.0005, 1.0011, 1.0016, 1.0009, 1.0010, 1.0013,\n",
       "                       1.0008])),\n",
       "              ('transformer_encoder.layers.1.norm2.bias',\n",
       "               tensor([-6.1939e-04,  6.5829e-04, -6.4747e-04,  5.5939e-04, -4.1158e-04,\n",
       "                       -6.0719e-04,  7.6249e-04,  9.3705e-04,  8.1052e-04, -5.5460e-04,\n",
       "                       -8.1274e-04, -4.0855e-04, -8.2060e-05, -5.8996e-04,  3.7852e-04,\n",
       "                       -7.2855e-04, -7.0273e-04,  5.8170e-04,  5.9733e-04, -8.4341e-04,\n",
       "                        8.0288e-04, -7.1514e-04, -7.0039e-04,  7.4957e-04, -6.7923e-04,\n",
       "                       -8.6348e-04, -4.3433e-04, -8.8162e-04, -7.3925e-04,  4.7627e-04,\n",
       "                       -8.2932e-04,  1.0262e-03, -6.2599e-04,  7.4962e-04, -8.3015e-04,\n",
       "                        1.0275e-03,  6.7624e-04, -5.9995e-04,  1.0058e-03, -6.2533e-04,\n",
       "                        6.3375e-04, -5.6669e-04, -7.8276e-04, -1.1867e-03,  3.9764e-04,\n",
       "                       -5.6610e-04,  9.1722e-04, -4.6993e-04, -7.3731e-04,  5.4294e-04,\n",
       "                       -5.5648e-04,  6.3355e-05, -6.0832e-05,  8.9948e-04, -1.0658e-03,\n",
       "                        1.0431e-03,  7.6331e-04,  7.7922e-04,  5.4727e-04, -2.5483e-04,\n",
       "                       -6.2230e-04, -7.2794e-04,  9.9671e-04, -6.8260e-04,  5.0112e-04,\n",
       "                        7.1366e-04,  2.8885e-04, -6.1503e-04, -7.3240e-04, -7.5559e-04,\n",
       "                        6.6078e-04,  7.3560e-04,  9.0329e-04, -9.7144e-05,  9.3483e-04,\n",
       "                        6.1286e-04, -5.9358e-04, -1.0828e-03, -5.3579e-04,  7.5239e-04,\n",
       "                        6.6727e-04, -5.2906e-04, -8.8019e-04, -7.6461e-04,  6.3652e-04,\n",
       "                       -7.7042e-04, -5.7218e-04, -6.1443e-04, -8.3044e-04, -7.0006e-04,\n",
       "                        1.1630e-03, -1.4695e-04, -2.0149e-04,  3.1696e-04,  6.6569e-04,\n",
       "                        7.2985e-04,  6.1188e-04,  6.9299e-04, -1.0178e-03, -8.0963e-04])),\n",
       "              ('encoder.weight',\n",
       "               tensor([[-0.0241,  0.0844, -0.0454,  ...,  0.0524,  0.0713, -0.0200],\n",
       "                       [ 0.0579, -0.0808,  0.0050,  ...,  0.0569, -0.0871, -0.0292],\n",
       "                       [-0.0384, -0.0313, -0.0991,  ..., -0.0995, -0.0272,  0.0234],\n",
       "                       ...,\n",
       "                       [-0.0763, -0.0582,  0.0742,  ...,  0.0970,  0.0776,  0.0128],\n",
       "                       [-0.0406, -0.0118,  0.0143,  ...,  0.0965, -0.0093, -0.0511],\n",
       "                       [ 0.0456,  0.0894,  0.0647,  ...,  0.0727, -0.0030,  0.0964]])),\n",
       "              ('encoder.bias',\n",
       "               tensor([-0.0346, -0.0849,  0.0377, -0.0511,  0.0977, -0.0213, -0.0408,  0.0619,\n",
       "                       -0.0169, -0.0743, -0.0571, -0.0780,  0.0466,  0.0597,  0.0029,  0.0054,\n",
       "                       -0.0527,  0.0732, -0.0014, -0.0337,  0.0679, -0.0696, -0.0400,  0.0449,\n",
       "                       -0.0094, -0.0917,  0.0971, -0.0778,  0.0589, -0.0260,  0.0898,  0.0026,\n",
       "                        0.0102,  0.0312,  0.0316, -0.0709,  0.0388, -0.0117,  0.0427, -0.0946,\n",
       "                       -0.0639,  0.0357, -0.0853, -0.0003, -0.0361, -0.0286,  0.0785,  0.0945,\n",
       "                        0.0343, -0.0821,  0.0268,  0.0079, -0.0227,  0.0442, -0.0892,  0.0862,\n",
       "                       -0.0191,  0.0375,  0.0041,  0.0731,  0.0455, -0.0497,  0.0633, -0.0267,\n",
       "                       -0.0228, -0.0581,  0.0425, -0.0337,  0.0877, -0.0579,  0.0422,  0.0937,\n",
       "                        0.0062, -0.0357, -0.0856, -0.0745,  0.0272, -0.0483,  0.0978,  0.0056,\n",
       "                       -0.0531, -0.0602, -0.0852,  0.0396, -0.0539, -0.0595, -0.0336,  0.0184,\n",
       "                       -0.0987,  0.0086,  0.0965,  0.0663,  0.0388, -0.0262,  0.0746,  0.0689,\n",
       "                       -0.0391, -0.0194,  0.0658,  0.0662])),\n",
       "              ('y_encoder.weight',\n",
       "               tensor([[-7.2919e-02],\n",
       "                       [-7.3289e-01],\n",
       "                       [ 6.1057e-01],\n",
       "                       [ 1.8863e-01],\n",
       "                       [-1.4184e-01],\n",
       "                       [ 3.6500e-01],\n",
       "                       [ 1.5917e-01],\n",
       "                       [ 3.4580e-01],\n",
       "                       [-1.3164e-01],\n",
       "                       [-7.1936e-01],\n",
       "                       [ 9.7991e-01],\n",
       "                       [ 1.5848e-01],\n",
       "                       [ 9.0841e-01],\n",
       "                       [ 3.6960e-01],\n",
       "                       [ 5.2012e-01],\n",
       "                       [ 9.0701e-01],\n",
       "                       [-8.3092e-01],\n",
       "                       [-8.1252e-01],\n",
       "                       [-8.6467e-01],\n",
       "                       [ 7.6254e-01],\n",
       "                       [-6.0345e-01],\n",
       "                       [ 8.8808e-02],\n",
       "                       [-1.7335e-01],\n",
       "                       [-2.8431e-01],\n",
       "                       [ 2.7647e-01],\n",
       "                       [ 8.3994e-02],\n",
       "                       [ 2.2084e-01],\n",
       "                       [ 5.4366e-01],\n",
       "                       [-7.3257e-01],\n",
       "                       [-7.1112e-01],\n",
       "                       [ 9.9302e-01],\n",
       "                       [ 6.6049e-01],\n",
       "                       [-7.8638e-01],\n",
       "                       [ 9.2670e-01],\n",
       "                       [ 4.5688e-01],\n",
       "                       [ 3.3710e-01],\n",
       "                       [ 8.1834e-01],\n",
       "                       [ 5.3209e-01],\n",
       "                       [ 6.7191e-01],\n",
       "                       [ 7.3582e-01],\n",
       "                       [-3.2765e-01],\n",
       "                       [ 5.5946e-02],\n",
       "                       [-1.9447e-01],\n",
       "                       [ 9.2975e-02],\n",
       "                       [-1.3015e-01],\n",
       "                       [-4.0273e-02],\n",
       "                       [-5.1224e-01],\n",
       "                       [-1.6163e-01],\n",
       "                       [ 7.8978e-01],\n",
       "                       [-5.7718e-04],\n",
       "                       [-7.2186e-01],\n",
       "                       [ 5.5394e-02],\n",
       "                       [ 9.1799e-01],\n",
       "                       [-3.4011e-01],\n",
       "                       [-9.4715e-01],\n",
       "                       [ 7.8185e-01],\n",
       "                       [-5.6916e-01],\n",
       "                       [ 9.0611e-01],\n",
       "                       [-3.6531e-01],\n",
       "                       [-5.2700e-02],\n",
       "                       [ 7.2824e-01],\n",
       "                       [-6.2679e-01],\n",
       "                       [ 8.8766e-01],\n",
       "                       [-4.6005e-01],\n",
       "                       [-6.2526e-01],\n",
       "                       [-7.9343e-01],\n",
       "                       [-9.6124e-01],\n",
       "                       [ 7.3597e-01],\n",
       "                       [ 4.1829e-01],\n",
       "                       [ 7.2067e-01],\n",
       "                       [ 6.1111e-01],\n",
       "                       [ 7.1169e-01],\n",
       "                       [-8.8360e-01],\n",
       "                       [-7.2887e-01],\n",
       "                       [-9.0678e-01],\n",
       "                       [ 1.9882e-01],\n",
       "                       [-6.8381e-01],\n",
       "                       [ 9.7649e-01],\n",
       "                       [ 1.0191e-01],\n",
       "                       [-9.7148e-01],\n",
       "                       [-9.7738e-01],\n",
       "                       [-5.6681e-01],\n",
       "                       [ 4.8829e-01],\n",
       "                       [-8.1783e-02],\n",
       "                       [-4.7541e-01],\n",
       "                       [ 9.6026e-01],\n",
       "                       [-3.9754e-01],\n",
       "                       [ 7.5933e-01],\n",
       "                       [-8.0116e-01],\n",
       "                       [ 6.3906e-01],\n",
       "                       [ 6.8926e-01],\n",
       "                       [-2.1531e-01],\n",
       "                       [ 7.4583e-01],\n",
       "                       [ 8.5125e-01],\n",
       "                       [-3.0200e-01],\n",
       "                       [ 8.3226e-01],\n",
       "                       [ 2.2861e-01],\n",
       "                       [ 1.0804e-01],\n",
       "                       [ 2.9106e-01],\n",
       "                       [ 4.5464e-01]])),\n",
       "              ('y_encoder.bias',\n",
       "               tensor([-0.2409, -0.7112,  0.4471, -0.4981, -0.2039, -0.9853, -0.5326,  0.6804,\n",
       "                       -0.4448, -0.0471,  0.6465,  0.5119,  0.1219, -0.0688, -0.3528,  0.8523,\n",
       "                        0.6600,  0.9446, -0.2165,  0.7919,  0.2827, -0.4113,  0.8107, -0.0551,\n",
       "                       -0.4373, -0.3832, -0.9729, -0.0011,  0.2876,  0.5089,  0.2679,  0.9005,\n",
       "                        0.3059, -0.0782, -0.8115,  0.8382,  0.2386, -0.5124,  0.0259,  0.0588,\n",
       "                       -0.4642,  0.0659, -0.4254, -0.0619,  0.3608, -0.3916, -0.4074,  0.0565,\n",
       "                        0.9532,  0.2065, -0.1600,  0.4833, -0.9091, -0.4988,  0.5124, -1.0005,\n",
       "                        0.0476, -0.4149,  0.5882, -0.9699, -0.6294,  0.5162, -0.4332,  0.2185,\n",
       "                        0.8052,  0.0328, -0.5878,  0.1769,  0.7778,  0.6483,  0.2215,  0.3838,\n",
       "                        0.2981,  0.2452, -0.9732, -0.0664, -0.7683, -0.9263, -0.9354,  0.2153,\n",
       "                       -0.4053, -0.9695, -0.9280, -0.1057,  0.9569, -0.6911, -0.6219,  0.8713,\n",
       "                        0.4214, -0.8874,  0.3429,  0.1436, -0.7299,  0.2255,  0.6498,  0.2861,\n",
       "                        0.6551,  0.2071,  0.9113, -0.5994])),\n",
       "              ('decoder.0.weight',\n",
       "               tensor([[-0.0861, -0.0245, -0.0027,  ...,  0.0930, -0.0811, -0.0693],\n",
       "                       [-0.0829,  0.0909, -0.0776,  ...,  0.0465,  0.0307, -0.0549],\n",
       "                       [ 0.0965, -0.0590,  0.0165,  ..., -0.0256,  0.0596, -0.0428],\n",
       "                       ...,\n",
       "                       [ 0.0399, -0.0600, -0.0892,  ..., -0.0541,  0.0932,  0.0882],\n",
       "                       [-0.0917, -0.0489,  0.0049,  ...,  0.0630, -0.0872,  0.0254],\n",
       "                       [-0.0746, -0.0444, -0.0693,  ..., -0.0407,  0.0852,  0.0009]])),\n",
       "              ('decoder.0.bias',\n",
       "               tensor([-0.0196,  0.0483,  0.0351,  ..., -0.0647,  0.0013, -0.0285])),\n",
       "              ('decoder.2.weight',\n",
       "               tensor([[-0.0003,  0.0040, -0.0059,  ...,  0.0130, -0.0090, -0.0014],\n",
       "                       [ 0.0257,  0.0184, -0.0055,  ..., -0.0115,  0.0017,  0.0236],\n",
       "                       [-0.0003,  0.0024, -0.0176,  ...,  0.0089, -0.0294,  0.0116],\n",
       "                       ...,\n",
       "                       [-0.0058,  0.0265, -0.0026,  ...,  0.0200,  0.0143, -0.0312],\n",
       "                       [-0.0106,  0.0223,  0.0130,  ...,  0.0173,  0.0120,  0.0035],\n",
       "                       [ 0.0218, -0.0116,  0.0097,  ...,  0.0288,  0.0059,  0.0180]])),\n",
       "              ('decoder.2.bias',\n",
       "               tensor([ 0.0073, -0.0108, -0.0284, -0.0042, -0.0202,  0.0239, -0.0001, -0.0066,\n",
       "                        0.0021,  0.0061])),\n",
       "              ('criterion.weight',\n",
       "               tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]))]),\n",
       " None,\n",
       " {'lr': 0.00014679684607496005,\n",
       "  'dropout': 0.0,\n",
       "  'emsize': 512,\n",
       "  'emsize_f': 100,\n",
       "  'batch_size': 2,\n",
       "  'nlayers': 2,\n",
       "  'num_features': 100,\n",
       "  'nhead': 64,\n",
       "  'nhid_factor': 2,\n",
       "  'bptt': 1152,\n",
       "  'eval_positions': [1094],\n",
       "  'seq_len_used': 50,\n",
       "  'sampling': 'normal',\n",
       "  'epochs': 400,\n",
       "  'num_steps': 1024,\n",
       "  'verbose': False,\n",
       "  'mix_activations': False,\n",
       "  'pre_sample_causes': True,\n",
       "  'multiclass_type': 'rank',\n",
       "  'nan_prob_unknown_reason_reason_prior': 0.5,\n",
       "  'categorical_feature_p': 0.2,\n",
       "  'nan_prob_no_reason': 0.0,\n",
       "  'nan_prob_unknown_reason': 0.0,\n",
       "  'nan_prob_a_reason': 0.0,\n",
       "  'max_num_classes': 10,\n",
       "  'num_classes': '<function <lambda>.<locals>.<lambda> at 0x7f87f73013a0>',\n",
       "  'noise_type': 'Gaussian',\n",
       "  'balanced': False,\n",
       "  'normalize_to_ranking': False,\n",
       "  'set_value_to_nan': 0.1,\n",
       "  'normalize_by_used_features': True,\n",
       "  'num_features_used': {'uniform_int_sampler_f(3,max_features)': '<function <lambda>.<locals>.<lambda> at 0x7f87f7301280>'},\n",
       "  'num_categorical_features_sampler_a': -1.0,\n",
       "  'differentiable_hyperparameters': {'prior_bag_exp_weights_1': {'distribution': 'uniform',\n",
       "    'min': 2.0,\n",
       "    'max': 10.0},\n",
       "   'num_layers': {'distribution': 'meta_gamma',\n",
       "    'max_alpha': 2,\n",
       "    'max_scale': 3,\n",
       "    'round': True,\n",
       "    'lower_bound': 2},\n",
       "   'prior_mlp_hidden_dim': {'distribution': 'meta_gamma',\n",
       "    'max_alpha': 3,\n",
       "    'max_scale': 100,\n",
       "    'round': True,\n",
       "    'lower_bound': 4},\n",
       "   'prior_mlp_dropout_prob': {'distribution': 'meta_beta',\n",
       "    'scale': 0.6,\n",
       "    'min': 0.1,\n",
       "    'max': 5.0},\n",
       "   'noise_std': {'distribution': 'meta_trunc_norm_log_scaled',\n",
       "    'max_mean': 0.3,\n",
       "    'min_mean': 0.0001,\n",
       "    'round': False,\n",
       "    'lower_bound': 0.0},\n",
       "   'init_std': {'distribution': 'meta_trunc_norm_log_scaled',\n",
       "    'max_mean': 10.0,\n",
       "    'min_mean': 0.01,\n",
       "    'round': False,\n",
       "    'lower_bound': 0.0},\n",
       "   'num_causes': {'distribution': 'meta_gamma',\n",
       "    'max_alpha': 3,\n",
       "    'max_scale': 7,\n",
       "    'round': True,\n",
       "    'lower_bound': 2},\n",
       "   'is_causal': {'distribution': 'meta_choice',\n",
       "    'choice_values': [True, False]},\n",
       "   'pre_sample_weights': {'distribution': 'meta_choice',\n",
       "    'choice_values': [True, False]},\n",
       "   'y_is_effect': {'distribution': 'meta_choice',\n",
       "    'choice_values': [True, False]},\n",
       "   'prior_mlp_activations': {'distribution': 'meta_choice_mixed',\n",
       "    'choice_values': [\"<class 'torch.nn.modules.activation.Tanh'>\",\n",
       "     \"<class 'torch.nn.modules.linear.Identity'>\",\n",
       "     \"<class 'torch.nn.modules.activation.ReLU'>\"]},\n",
       "   'block_wise_dropout': {'distribution': 'meta_choice',\n",
       "    'choice_values': [True, False]},\n",
       "   'sort_features': {'distribution': 'meta_choice',\n",
       "    'choice_values': [True, False]},\n",
       "   'in_clique': {'distribution': 'meta_choice',\n",
       "    'choice_values': [True, False]},\n",
       "   'outputscale': {'distribution': 'meta_trunc_norm_log_scaled',\n",
       "    'max_mean': 10.0,\n",
       "    'min_mean': 1e-05,\n",
       "    'round': False,\n",
       "    'lower_bound': 0},\n",
       "   'lengthscale': {'distribution': 'meta_trunc_norm_log_scaled',\n",
       "    'max_mean': 10.0,\n",
       "    'min_mean': 1e-05,\n",
       "    'round': False,\n",
       "    'lower_bound': 0},\n",
       "   'noise': {'distribution': 'meta_choice',\n",
       "    'choice_values': [1e-05, 0.0001, 0.01]}},\n",
       "  'prior_type': 'mlp',\n",
       "  'differentiable': True,\n",
       "  'flexible': True,\n",
       "  'recompute_attn': False,\n",
       "  'bptt_extra_samples': None,\n",
       "  'output_multiclass_ordered_p': 0.0,\n",
       "  'multiclass_loss_type': 'nono',\n",
       "  'normalize_with_sqrt': False,\n",
       "  'new_mlp_per_example': True,\n",
       "  'prior_mlp_scale_weights_sqrt': True,\n",
       "  'batch_size_per_gp_sample': None,\n",
       "  'normalize_ignore_label_too': False,\n",
       "  'differentiable_hps_as_style': False,\n",
       "  'max_eval_pos': 1000,\n",
       "  'random_feature_rotation': True,\n",
       "  'rotate_normalized_labels': True,\n",
       "  'canonical_y_encoder': False,\n",
       "  'aggregate_k_gradients': 8,\n",
       "  'total_available_time_in_s': None,\n",
       "  'train_mixed_precision': True,\n",
       "  'efficient_eval_masking': True,\n",
       "  'epoch_in_training': 0.005})"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.load('/Users/antanas/GitRepo/TabPFN/tabpfn/models_diff/prior_diff_real_checkpoint_Second_test__n_0_epoch_1.cpkt',\n",
    "           map_location=torch.device('cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TabPFN",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "65357cc1be7833c29b4339c6d26182986ed5bca65cc0295a91b0be540d4badb4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
